ğŸ¤– æœ¬åœ° AI åŠ©æ‰‹å®‰è£… - åŸºç¡€é…ç½®å™¨

æè¿°

è¿™æ˜¯ä¸€ä¸ªè‡ªåŠ¨å®‰è£…è„šæœ¬ï¼Œç”¨äºé…ç½®åŸºç¡€æœ¬åœ° AI åŠ©æ‰‹ï¼Œä½¿ç”¨ llama.cpp æ¨¡å‹ã€‚è¯¥å®‰è£…å™¨è®¾è®¡ç®€å•ã€ç›´è§‚ã€æ˜“ç”¨ï¼Œä¸ºä¸æœ¬åœ°è¯­è¨€æ¨¡å‹äº¤äº’æä¾›äº†ç¨³å›ºçš„åŸºç¡€ã€‚

ä¸»è¦ç‰¹æ€§

ğŸ”§ ç®€å•ç›´è§‚çš„é…ç½®
	â€¢	å¼•å¯¼å®‰è£…ï¼šäº¤äº’å¼åˆ†æ­¥é…ç½®
	â€¢	è‡ªåŠ¨éªŒè¯ï¼šæ£€æŸ¥å…ˆå†³æ¡ä»¶å’Œè·¯å¾„æœ‰æ•ˆæ€§
	â€¢	è‡ªé€‚åº”é…ç½®ï¼šé€‚åº”ä¸åŒç¯å¢ƒ
	â€¢	æ¨¡å—åŒ–ç»“æ„ï¼šç»„ç»‡è‰¯å¥½ä¸”å¯æ‰©å±•

ğŸ¯ æ ¸å¿ƒåŠŸèƒ½
	â€¢	LLM å®¢æˆ·ç«¯ï¼šç›´æ¥ä¸ llama.cpp é€šä¿¡
	â€¢	æ–‡ä»¶ç®¡ç†å™¨ï¼šå®‰å…¨çš„è¯»å†™æ“ä½œ
	â€¢	å‘½ä»¤æ‰§è¡Œå™¨ï¼šå—æ§æ‰§è¡Œç³»ç»Ÿå‘½ä»¤
	â€¢	çµæ´»é…ç½®ï¼šå¯é€šè¿‡ JSON æ–‡ä»¶é…ç½®

ğŸ“ æ¨¡å—åŒ–æ¶æ„

src/
â”œâ”€â”€ core/           # åŠ©æ‰‹ä¸»å¼•æ“
â”œâ”€â”€ llm/            # llama.cpp å®¢æˆ·ç«¯
â”œâ”€â”€ file_ops/       # æ–‡ä»¶ç®¡ç†
â””â”€â”€ commands/       # å‘½ä»¤æ‰§è¡Œ

ç³»ç»Ÿè¦æ±‚
	â€¢	Python 3.11+
	â€¢	å·²ç¼–è¯‘çš„ llama.cpp
	â€¢	å…¼å®¹ GGUF æ¨¡å‹
	â€¢	Python pip3
	â€¢	æ“ä½œç³»ç»Ÿï¼šmacOS, Linux

å¿«é€Ÿå®‰è£…

1. ä¸‹è½½ä¸è¿è¡Œ

# ä¸‹è½½è„šæœ¬
curl -O https://raw.githubusercontent.com/tu-usuario/asistente-basico/main/setup_asistente_basico.sh

# æ·»åŠ æ‰§è¡Œæƒé™
chmod +x setup_asistente_basico.sh

# æ‰§è¡Œå®‰è£…
./setup_asistente_basico.sh

2. äº¤äº’å¼é…ç½®

è„šæœ¬å°†æç¤ºä½ è¾“å…¥ï¼š

é¡¹ç›®ç›®å½•ï¼š

é¡¹ç›®ç›®å½• [/Users/tu-usuario/asistente-ia]: 

GGUF æ¨¡å‹è·¯å¾„ï¼š

GGUF æ¨¡å‹è·¯å¾„ [/Users/tu-usuario/modelo/modelo.gguf]: 

llama-cli è·¯å¾„ï¼š

llama.cpp è·¯å¾„ [/Users/tu-usuario/llama.cpp/build/bin/llama-cli]: 

3. ç¡®è®¤

å·²é€‰æ‹©é…ç½®ï¼š
é¡¹ç›®ç›®å½•: /Users/tu-usuario/asistente-ia
æ¨¡å‹: /Users/tu-usuario/modelo/modelo.gguf
Llama.cpp: /Users/tu-usuario/llama.cpp/build/bin/llama-cli

æ˜¯å¦ç»§ç»­æ­¤é…ç½®ï¼Ÿ (y/N)

ç”Ÿæˆçš„ç›®å½•ç»“æ„

asistente-ia/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                 # ä¸»å…¥å£
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ assistant.py        # ä¸»åŠ©æ‰‹ç±»
â”‚   â”‚   â””â”€â”€ config.py           # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â””â”€â”€ client.py           # llama.cpp å®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ file_ops/
â”‚   â”‚   â””â”€â”€ manager.py          # æ–‡ä»¶ç®¡ç†
â”‚   â””â”€â”€ commands/
â”‚       â””â”€â”€ runner.py           # å‘½ä»¤æ‰§è¡Œ
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.json           # ä¸»é…ç½®æ–‡ä»¶
â”œâ”€â”€ tools/                      # é™„åŠ å·¥å…·
â”œâ”€â”€ tests/                      # ç³»ç»Ÿæµ‹è¯•
â”œâ”€â”€ logs/                       # æ—¥å¿—æ–‡ä»¶
â””â”€â”€ examples/                   # ç¤ºä¾‹

åŸºæœ¬ä½¿ç”¨

ä¸»å‘½ä»¤

cd /è·¯å¾„/åˆ°/ä½ çš„/asistente-ia
python3 src/main.py "åˆ—å‡ºé¡¹ç›®ä¸­æœ‰å“ªäº› Python æ–‡ä»¶ï¼Ÿ"

äº¤äº’æ¨¡å¼

python3 src/main.py
ğŸ¤– æœ¬åœ° AI åŠ©æ‰‹ - äº¤äº’æ¨¡å¼
è¾“å…¥ 'exit' é€€å‡ºï¼Œè¾“å…¥ 'help' è·å–å¸®åŠ©

ğŸ’¬ > è§£é‡Š main.py æ–‡ä»¶
ğŸ¤– main.py æ˜¯ä¸»å…¥å£æ–‡ä»¶...

ğŸ’¬ > exit
å†è§ï¼ğŸ‘‹

å‘½ä»¤è¡Œå‚æ•°

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
python3 src/main.py --config config/custom.json "åˆ†ææ­¤é¡¹ç›®"

# verbose æ¨¡å¼
python3 src/main.py --verbose "åˆ—å‡ºæ‰€æœ‰ Python æ–‡ä»¶"

# å¸®åŠ©
python3 src/main.py --help

é…ç½®

é…ç½®æ–‡ä»¶ (config/settings.json)

{
  "llm": {
    "model_path": "/è·¯å¾„/åˆ°/ä½ çš„/modelo.gguf",
    "llama_bin": "/è·¯å¾„/åˆ°/llama-cli",
    "max_tokens": 1024,
    "temperature": 0.7
  },
  "assistant": {
    "safe_mode": true,
    "backup_files": true,
    "max_file_size": 1048576,
    "supported_extensions": [".py", ".js", ".ts", ".json", ".md", ".txt", ".sh"]
  },
  "logging": {
    "level": "INFO",
    "file": "logs/assistant.log"
  }
}

LLM å‚æ•°è‡ªå®šä¹‰
	â€¢	max_tokensï¼šå“åº”æœ€å¤§é•¿åº¦
	â€¢	temperatureï¼šåˆ›é€ æ€§ï¼ˆ0.0=ç¡®å®šæ€§, 1.0=åˆ›é€ æ€§ï¼‰
	â€¢	model_pathï¼šGGUF æ¨¡å‹è·¯å¾„
	â€¢	llama_binï¼šllama-cli äºŒè¿›åˆ¶è·¯å¾„

å®‰å…¨é…ç½®
	â€¢	safe_modeï¼šå¯ç”¨å‘½ä»¤å®‰å…¨æ¨¡å¼
	â€¢	backup_filesï¼šä¿®æ”¹å‰åˆ›å»ºå¤‡ä»½
	â€¢	max_file_sizeï¼šå¤„ç†æ–‡ä»¶çš„æœ€å¤§å¤§å°
	â€¢	supported_extensionsï¼šæ”¯æŒçš„æ–‡ä»¶ç±»å‹

æ ¸å¿ƒåŠŸèƒ½

1. æ–‡ä»¶åˆ†æ

python3 src/main.py "è§£é‡Š config.py æ–‡ä»¶çš„åŠŸèƒ½"

2. æ–‡ä»¶åˆ—è¡¨

python3 src/main.py "åˆ—å‡ºé¡¹ç›®ä¸­æ‰€æœ‰ Python æ–‡ä»¶"

3. ç»“æ„åˆ†æ

python3 src/main.py "æè¿°æ­¤é¡¹ç›®çš„æ¶æ„"

4. ä»£ç å¸®åŠ©

python3 src/main.py "å¦‚ä½•ä¼˜åŒ– load_config å‡½æ•°ï¼Ÿ"

å¯ç”¨å‘½ä»¤

å¸®åŠ©å‘½ä»¤
	â€¢	help - æ˜¾ç¤ºå®Œæ•´å¸®åŠ©
	â€¢	exit - é€€å‡ºäº¤äº’æ¨¡å¼

æŸ¥è¯¢ç¤ºä¾‹
	â€¢	â€œè§£é‡Š X æ–‡ä»¶â€
	â€¢	â€œåˆ—å‡º Y ç±»å‹æ–‡ä»¶â€
	â€¢	â€œæè¿°é¡¹ç›®ç»“æ„â€
	â€¢	â€œç±» Z çš„ä½œç”¨â€
	â€¢	â€œå‡½æ•° W çš„åŠŸèƒ½â€

éªŒè¯ä¸å®‰å…¨

è‡ªåŠ¨éªŒè¯
	â€¢	âœ… æ£€æŸ¥ Python 3.11+
	â€¢	âœ… æ£€æŸ¥ pip3
	â€¢	âœ… éªŒè¯ llama-cli è·¯å¾„
	â€¢	âœ… éªŒè¯ GGUF æ¨¡å‹
	â€¢	âš ï¸ æœªæ‰¾åˆ°æ–‡ä»¶çš„è­¦å‘Š

å®‰å…¨æ¨¡å¼

{
  "assistant": {
    "safe_mode": true,     
    "backup_files": true,  
    "max_file_size": 1048576
  }
}

æ‰©å±•ä¸è‡ªå®šä¹‰

æ·»åŠ æ–°æ–‡ä»¶ç±»å‹

{
  "assistant": {
    "supported_extensions": [".py", ".js", ".go", ".rust", ".cpp"]
  }
}

ä¿®æ”¹æç¤ºè¯

ç¼–è¾‘ src/core/assistant.py ä¸­çš„ _build_prompt() æ–¹æ³•ï¼š

def _build_prompt(self, context: Dict, user_input: str) -> str:
    prompt = f"""ä½ æ˜¯ {your_domain} é¢†åŸŸçš„ä¸“ç”¨åŠ©æ‰‹ã€‚
    
    CONTEXT: {context}
    QUERY: {user_input}
    
    è¯·ä»¥ {your_style} é£æ ¼å›ç­”ã€‚"""
    
    return prompt

æ·»åŠ æ–°å‘½ä»¤

ä¿®æ”¹ src/commands/runner.py ä»¥åŒ…å«æ–°çš„å…è®¸å‘½ä»¤ï¼š

self.safe_commands = {
    'ls', 'cat', 'grep', 'find',  
    'git', 'npm', 'pip',           
    'your_custom_command'          
}

æ•…éšœæ’é™¤

é”™è¯¯ï¼šâ€œPython3 æœªå®‰è£…â€

# macOS
brew install python@3.11

# Ubuntu/Debian
sudo apt update && sudo apt install python3.11

é”™è¯¯ï¼šâ€œllama-cli æœªæ‰¾åˆ°â€

# æ£€æŸ¥ llama.cpp å®‰è£…
ls -la /è·¯å¾„/åˆ°/llama.cpp/build/bin/llama-cli

# æ›´æ–°é…ç½®è·¯å¾„
vim config/settings.json

é”™è¯¯ï¼šâ€œæ¨¡å‹æœªæ‰¾åˆ°â€

# æ£€æŸ¥æ¨¡å‹è·¯å¾„
ls -la /è·¯å¾„/åˆ°/ä½ çš„/modelo.gguf

# å¦‚æœ‰å¿…è¦ä¸‹è½½æ¨¡å‹
wget https://huggingface.co/modelo/resolve/main/modelo.gguf

æ€§èƒ½é—®é¢˜

{
  "llm": {
    "max_tokens": 512,      
    "temperature": 0.3      
  }
}

ç¼–è¾‘å™¨é›†æˆ

VSCode

// tasks.json
{
    "label": "æŸ¥è¯¢åŠ©æ‰‹",
    "type": "shell",
    "command": "python3",
    "args": ["src/main.py", "${input:consulta}"],
    "group": "build"
}

Vim/NeoVim

" å¿«æ·é”®è°ƒç”¨åŠ©æ‰‹
nnoremap <leader>ai :!python3 src/main.py "<C-R><C-W>"<CR>

è´¡çŒ®ä¸å¼€å‘

è´¡çŒ®æµç¨‹
	1.	Fork ä»“åº“
	2.	åˆ›å»ºåˆ†æ”¯ï¼šgit checkout -b feature/nueva-funcionalidad
	3.	åœ¨ç°æœ‰æ¨¡å—åŒ–æ¶æ„ä¸­å¼€å‘
	4.	åœ¨ tests/ æ·»åŠ æµ‹è¯•
	5.	åœ¨ examples/ æ·»åŠ æ–‡æ¡£
	6.	åˆ›å»º Pull Request

å¼€å‘æŒ‡å—
	â€¢	éµå¾ªç°æœ‰æ¨¡å—åŒ–æ¶æ„
	â€¢	ä¸ºæ–°åŠŸèƒ½æ·»åŠ éªŒè¯
	â€¢	ä¿æŒ JSON é…ç½®å…¼å®¹æ€§
	â€¢	åŒ…å«é€‚å½“çš„æ—¥å¿—è®°å½•

è®¸å¯è¯

MIT License

ä½œè€…

Gustavo Silva da Costa (Eto Demerzel)

ç‰ˆæœ¬

1.0.0 - åŸºç¡€é…ç½®å™¨ï¼Œæ¨¡å—åŒ–æ¶æ„ç¨³å›º

â¸»

