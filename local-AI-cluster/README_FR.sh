ğŸ¤– AI Cluster â€“ SystÃ¨me DistribuÃ© dâ€™Intelligence Artificielle

Traite des requÃªtes dâ€™IA en parallÃ¨le Ã  lâ€™aide de plusieurs machines de ton rÃ©seau local (intranet).

Sans cloud â€¢ PrivÃ© â€¢ Ã‰volutif â€¢ Open Source

â¸»

ğŸ“‹ Description

AI Cluster est un systÃ¨me permettant dâ€™exploiter les ordinateurs inactifs dâ€™un rÃ©seau local pour exÃ©cuter des modÃ¨les dâ€™IA de maniÃ¨re distribuÃ©e.
IdÃ©al pour les entreprises souhaitant :
	â€¢	âœ… ConfidentialitÃ© totale â€“ Les donnÃ©es ne quittent jamais ton rÃ©seau
	â€¢	âœ… Aucun coÃ»t cloud â€“ Utilise le matÃ©riel existant
	â€¢	âœ… ConformitÃ© RGPD â€“ Tout reste dans ton infrastructure
	â€¢	âœ… Ã‰volutivitÃ© â€“ Ajoute facilement de nouvelles machines
	â€¢	âœ… Traitement parallÃ¨le â€“ Les requÃªtes sont exÃ©cutÃ©es simultanÃ©ment

â¸»

ğŸš€ Cas dâ€™Utilisation

Pour les Entreprises
	â€¢	Traiter plusieurs requÃªtes IA via les ordinateurs du bureau
	â€¢	Analyse distribuÃ©e de documents
	â€¢	GÃ©nÃ©ration de contenu en parallÃ¨le
	â€¢	Automatisation de tÃ¢ches rÃ©pÃ©titives

Pour les DÃ©veloppeurs
	â€¢	ExpÃ©rimenter avec les systÃ¨mes distribuÃ©s
	â€¢	Apprendre la parallÃ©lisation
	â€¢	Tester les performances des modÃ¨les
	â€¢	Prototyper rapidement des solutions

â¸»

ğŸ¯ CaractÃ©ristiques
	â€¢	âœ¨ Assistant interactif â€“ Configuration guidÃ©e pas Ã  pas
	â€¢	ğŸ” Configuration SSH automatique â€“ Connexions sans mot de passe
	â€¢	ğŸŒ Multi-machines â€“ Supporte N ordinateurs du rÃ©seau
	â€¢	âš–ï¸ RÃ©partition round-robin â€“ Charge Ã©quilibrÃ©e entre hÃ´tes
	â€¢	ğŸ“Š Statistiques dÃ©taillÃ©es â€“ Suivi du traitement
	â€¢	ğŸ›¡ï¸ Gestion dâ€™erreurs robuste â€“ Continue mÃªme en cas dâ€™Ã©chec dâ€™une machine

â¸»

ğŸ“¦ PrÃ©requis

Sur TOUTES les machines :
	1.	llama.cpp compilÃ©

git clone https://github.com/ggerganov/llama.cpp
cd llama.cpp
make


	2.	ModÃ¨le GGUF tÃ©lÃ©chargÃ©
	â€¢	Mistral, Llama, Qwen, etc.
	â€¢	PlacÃ© au mÃªme chemin sur chaque machine
	3.	SSH activÃ© (uniquement sur les machines distantes)

# macOS
sudo systemsetup -setremotelogin on

# Linux
sudo systemctl enable ssh
sudo systemctl start ssh



â¸»

âš™ï¸ Installation

1. TÃ©lÃ©charger le script

# Cloner le dÃ©pÃ´t
git clone https://github.com/BiblioGalactic/ai-cluster
cd ai-cluster

# Ou tÃ©lÃ©charger directement
curl -O https://raw.githubusercontent.com/BiblioGalactic/ai-cluster/main/ai-cluster.sh
chmod +x ai-cluster.sh

2. PremiÃ¨re configuration

./ai-cluster.sh setup

Lâ€™assistant te guidera pour :
	â€¢	âœ… DÃ©tecter llama.cpp et les modÃ¨les locaux
	â€¢	âœ… Configurer les IPs des machines distantes
	â€¢	âœ… Configurer SSH sans mot de passe
	â€¢	âœ… VÃ©rifier la connectivitÃ© et les fichiers

â¸»

ğŸ“– Utilisation

Commande de base

./ai-cluster.sh run queries.txt

Fichier de requÃªtes

CrÃ©e un fichier queries.txt avec tes questions (une par ligne) :

Explique ce quâ€™est un rÃ©seau neuronal  
RÃ©sume la thÃ©orie de la relativitÃ©  
Quelle est la capitale du Japon ?  
Ã‰cris un haÃ¯ku sur la technologie  

Autres commandes

# Voir la configuration actuelle
./ai-cluster.sh config

# Tester la connectivitÃ©
./ai-cluster.sh test

# Reconfigurer
./ai-cluster.sh setup

# Aide
./ai-cluster.sh help


â¸»

ğŸ—ï¸ Architecture

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ai-cluster.sh (Orchestrateur)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                â”‚              â”‚          â”‚
  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
  â”‚ Local  â”‚      â”‚ PC 1   â”‚    â”‚ PC 2   â”‚ â”‚ PC N   â”‚
  â”‚ (Mac)  â”‚      â”‚ (SSH)  â”‚    â”‚ (SSH)  â”‚ â”‚ (SSH)  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  Query 1,5,9     Query 2,6,10  Query 3,7  Query 4,8

RÃ©partition round-robin :
	â€¢	RequÃªte #1 â†’ Machine locale
	â€¢	RequÃªte #2 â†’ Machine distante 1
	â€¢	RequÃªte #3 â†’ Machine distante 2
	â€¢	RequÃªte #4 â†’ Machine distante 3
	â€¢	RequÃªte #5 â†’ Retour Ã  la machine locale

â¸»

ğŸ”§ Configuration AvancÃ©e

Fichier .ai_cluster_config

AprÃ¨s la configuration, ce fichier est crÃ©Ã© :

# Machine locale
LOCAL_LLAMA="/Users/user/modelo/llama.cpp/build/bin/llama-cli"
LOCAL_MODEL="/Users/user/modelo/mistral-7b.gguf"

# Machines distantes (sÃ©parÃ©es par des virgules)
REMOTE_IPS="192.168.1.82,192.168.1.83"
REMOTE_USER="username"
REMOTE_LLAMA="/home/user/llama.cpp/build/bin/llama-cli"
REMOTE_MODEL="/home/user/mistral-7b.gguf"

# DÃ©lai entre connexions SSH (en secondes)
REMOTE_DELAY=10

Tu peux le modifier manuellement si nÃ©cessaire.

â¸»

ğŸ“Š Exemple de Sortie

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     ğŸ¤– AI CLUSTER â€“ SystÃ¨me DistribuÃ© dâ€™IA ğŸ¤–             â•‘
â•‘   Traite des requÃªtes en parallÃ¨le sur ton rÃ©seau local   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[17:30:00] ğŸ¯ Total de requÃªtes : 20  
[i] Machines disponibles : 3 (1 locale + 2 distantes)

[17:30:00] ğŸ’» [Locale] RequÃªte #1 : Explique ce quâ€™est un rÃ©seau neuronalâ€¦  
[17:30:00] ğŸŒ [192.168.1.82] RequÃªte #2 : RÃ©sume la thÃ©orieâ€¦  
[17:30:00] ğŸŒ [192.168.1.83] RequÃªte #3 : Quelle est la capitaleâ€¦  
[17:30:02] âœ“ [Locale] RequÃªte #1 terminÃ©e  
[17:30:15] âœ“ [192.168.1.82] RequÃªte #2 terminÃ©e  
[17:30:18] âœ“ [192.168.1.83] RequÃªte #3 terminÃ©e  

...

[17:35:00] â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  
[17:35:00] âœ“ âœ¨ TERMINÃ‰  
[17:35:00] â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  
[i] Total traitÃ© : 20 requÃªtes  
[i] RÃ©sultats dans : results_cluster/  


â¸»

ğŸ› DÃ©pannage

SSH demande un mot de passe Ã  chaque fois

# Relance le setup pour configurer ssh-copy-id
./ai-cluster.sh setup

â€œllama-cli introuvableâ€ sur machine distante

VÃ©rifie le chemin dans .ai_cluster_config :

# Sur la machine distante
which llama-cli
# Ou cherche
find ~ -name "llama-cli" 2>/dev/null

Les requÃªtes ne se traitent pas

# Tester la connectivitÃ©
./ai-cluster.sh test

# VÃ©rifier les journaux individuels
cat results_cluster/result_2_*.txt

Script lent sur Mac Mini

Les scripts automatiques dans .zshrc peuvent ralentir SSH.
Ajoute au dÃ©but du .zshrc des machines distantes :

# DÃ©sactiver pour SSH non interactif
[[ -n "$SSH_CONNECTION" ]] && [[ ! -t 0 ]] && return


â¸»

ğŸ¤ Contribuer

Les contributions sont les bienvenues !
	1.	Fork le projet
	2.	CrÃ©e une branche (git checkout -b feature/AmazingFeature)
	3.	Commit tes modifications (git commit -m 'Ajout de AmazingFeature')
	4.	Push la branche (git push origin feature/AmazingFeature)
	5.	Ouvre une Pull Request

â¸»

ğŸ“ Feuille de Route
	â€¢	Tableau de bord web en temps rÃ©el
	â€¢	Support Docker containers
	â€¢	DÃ©tection automatique des machines du rÃ©seau
	â€¢	Cache des rÃ©sultats
	â€¢	SystÃ¨me de prioritÃ©s
	â€¢	MÃ©triques de performance
	â€¢	IntÃ©gration Kubernetes

â¸»

ğŸ“„ Licence

Licence MIT â€“ voir le fichier LICENSE

â¸»

ğŸ‘¨â€ğŸ’» Auteur

Gustavo Silva da Costa (BiblioGalactic)
	â€¢	GitHub : @BiblioGalactic
	â€¢	Projet : RÃ©alisme cybernÃ©tique appliquÃ© Ã  lâ€™infrastructure dâ€™entreprise

â¸»

ğŸ™ Remerciements
	â€¢	llama.cpp â€“ Moteur dâ€™infÃ©rence
	â€¢	Anthropic Claude â€“ Assistance au dÃ©veloppement
	â€¢	CommunautÃ© open-source de lâ€™IA locale

â¸»

âš ï¸ Avertissement

Ce logiciel est fourni â€œtel quelâ€, sans aucune garantie.
Son utilisation se fait Ã  tes propres risques.
Les auteurs ne sont pas responsables de pertes de donnÃ©es,
de dysfonctionnements matÃ©riels ou de tout dommage liÃ© Ã  son usage.

â¸»

ğŸ“š Ressources
	â€¢	Documentation de llama.cpp
	â€¢	ModÃ¨les GGUF disponibles
	â€¢	Configuration SSH sans mot de passe

â¸»

Si ce projet tâ€™est utile, laisse-lui une â­ sur GitHub !
