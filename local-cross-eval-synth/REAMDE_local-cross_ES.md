# ü§ñ Local-CROS: Cross-Referential Optimization System

## Descripci√≥n

**Local-CROS** es un sistema avanzado de evaluaci√≥n cruzada para modelos LLaMA locales que permite comparar respuestas entre m√∫ltiples modelos y generar respuestas optimizadas mediante s√≠ntesis inteligente. El sistema implementa un enfoque √∫nico de evaluaci√≥n mutua donde cada modelo eval√∫a las respuestas de los dem√°s.

## Caracter√≠sticas Principales

### üîÑ Evaluaci√≥n Cruzada
- **Evaluaci√≥n mutua**: Cada modelo eval√∫a las respuestas de todos los otros
- **M√∫ltiples perspectivas**: Obt√©n diferentes enfoques para la misma pregunta
- **Puntuaci√≥n autom√°tica**: Sistema de scoring autom√°tico para cada respuesta
- **Historial completo**: Registro detallado de todas las interacciones

### üéØ S√≠ntesis Inteligente
- **Detecci√≥n autom√°tica de tipo de contenido**: C√≥digo, listas, poes√≠a, di√°logos, etc.
- **Combinaci√≥n optimizada**: Fusiona las mejores partes de cada respuesta
- **Eliminaci√≥n de redundancias**: Evita informaci√≥n repetida
- **Recomendaciones contextuales**: Sugerencias espec√≠ficas seg√∫n el tipo de contenido

### üìä Sistema de Archivos Incrementales
- **Numeraci√≥n autom√°tica**: `modelo1.txt`, `modelo2.txt`, etc.
- **Historial acumulativo**: Todas las ejecuciones en un archivo central
- **Timestamps detallados**: Registro temporal de cada operaci√≥n
- **Trazabilidad completa**: Seguimiento de toda la evoluci√≥n

## Requisitos del Sistema

- **llama.cpp** compilado y funcional
- **2-4 modelos GGUF** compatibles
- **Bash 4.0+**
- **Herramientas b√°sicas**: `find`, `sed`, `sort`, `jq` (opcional)
- **Sistema operativo**: macOS, Linux

## Instalaci√≥n

### 1. Descarga
```bash
# Clonar repositorio
git clone https://github.com/tu-usuario/local-cros.git
cd local-cros

# Hacer ejecutable
chmod +x local-cros.sh
```

### 2. Primera Configuraci√≥n
```bash
# Ejecutar por primera vez (configuraci√≥n interactiva)
./local-cros.sh
```

El script te pedir√°:
- **Ruta de llama-cli**: Ubicaci√≥n del binario llama.cpp
- **Directorio de trabajo**: Donde guardar resultados
- **Configuraci√≥n de modelos**: Nombre y ruta de cada modelo (2-4 modelos)

### 3. Archivo de Configuraci√≥n Generado
```bash
# local-cros.conf
LLAMA_CLI_PATH="/path/to/llama-cli"
WORK_DIR="./results"

MODEL_1_NAME="mistral"
MODEL_1_PATH="/path/to/mistral.gguf"

MODEL_2_NAME="llama"
MODEL_2_PATH="/path/to/llama.gguf"
# ... etc
```

## Uso

### Modo Interactivo
```bash
./local-cros.sh
What do you need?
> Escribe un poema √©pico sobre programaci√≥n en Python
```

### Modo Comando Directo
```bash
./local-cros.sh "Explica las diferencias entre React y Vue.js"
```

### Ejemplo de Salida
```
ü§ñ Starting model comparison for: "Explica programaci√≥n funcional"

==> Consulting mistral...
[mistral] says: La programaci√≥n funcional es un paradigma...
---

==> Consulting llama...
[llama] says: En programaci√≥n funcional, las funciones son...
---

=== CROSS-EVALUATION BETWEEN MODELS ===
=== EVALUATION WITH MISTRAL ===
Evaluating llama: La respuesta es precisa y bien estructurada...

=== COMBINING BEST RESPONSES ===
üíª Combined response generated and saved!
üìã Complete history in: ./results/complete_history.txt
```

## Estructura de Archivos Generados

```
results/
‚îú‚îÄ‚îÄ responses/
‚îÇ   ‚îú‚îÄ‚îÄ mistral1.txt, mistral2.txt, mistral3.txt...
‚îÇ   ‚îú‚îÄ‚îÄ llama1.txt, llama2.txt, llama3.txt...
‚îÇ   ‚îú‚îÄ‚îÄ codellama1.txt, codellama2.txt...
‚îÇ   ‚îî‚îÄ‚îÄ response_combined_final.txt
‚îî‚îÄ‚îÄ complete_history.txt
```

## Funcionalidades Avanzadas

### Detecci√≥n Autom√°tica de Tipo de Contenido

El sistema detecta autom√°ticamente el tipo de contenido y optimiza seg√∫n el contexto:

- **C√≥digo**: `python`, `javascript`, `bash`, `c++`
- **Listas**: Instrucciones paso a paso
- **Poes√≠a**: Haikus, versos, estrofas
- **Di√°logos**: Conversaciones, guiones
- **Texto general**: Explicaciones, ensayos

### Sistema de Evaluaci√≥n

Cada modelo eval√∫a las respuestas usando criterios espec√≠ficos:
- **Precisi√≥n t√©cnica**
- **Claridad de explicaci√≥n**
- **Completitud de la respuesta**
- **Relevancia al contexto**

### Recomendaciones Contextuales

```bash
# Para c√≥digo
üíª Recomendaci√≥n: Ejecuta 'python3 respuesta_final.py' para probar

# Para listas
üìã Recomendaci√≥n: Guarda como PDF o comparte como instrucciones

# Para poes√≠a
üé≠ Recomendaci√≥n: Perfecto para an√°lisis literario

# Para di√°logos
üé¨ Recomendaci√≥n: Ideal para guiones o role-playing
```

## Configuraci√≥n Avanzada

### Par√°metros de Modelo
```bash
# Editar local-cros.sh para ajustar par√°metros
-n 200           # N√∫mero m√°ximo de tokens
--temp 0.7       # Temperatura (creatividad)
--top-k 40       # Top-k sampling
--top-p 0.9      # Top-p sampling
--repeat-penalty 1.1  # Penalizaci√≥n por repetici√≥n
```

### Personalizaci√≥n de Evaluaci√≥n
```bash
# Modificar el prompt de evaluaci√≥n en la funci√≥n evaluate_response()
local evaluation_prompt="Eval√∫a esta respuesta usando estos criterios..."
```

## Casos de Uso

### 1. Desarrollo de Software
```bash
./local-cros.sh "Optimiza este algoritmo de ordenamiento burbuja"
# Obt√©n m√∫ltiples enfoques de optimizaci√≥n
```

### 2. Escritura Creativa
```bash
./local-cros.sh "Escribe un di√°logo entre S√≥crates y Steve Jobs sobre √©tica"
# Combina diferentes estilos narrativos
```

### 3. An√°lisis T√©cnico
```bash
./local-cros.sh "Explica las ventajas y desventajas de microservicios"
# M√∫ltiples perspectivas t√©cnicas combinadas
```

### 4. Resoluci√≥n de Problemas
```bash
./local-cros.sh "C√≥mo debuggear un memory leak en C++"
# Diferentes enfoques de debugging
```

## M√©tricas y An√°lisis

### Historial Completo
El archivo `complete_history.txt` contiene:
```
#=== EXECUTION 2025-01-21 15:30:15 ===
MODEL: mistral1
QUESTION: ¬øQu√© es machine learning?
RESPONSE: Machine learning es una rama de la IA...

#=== EVALUATION 2025-01-21 15:30:45 ===
EVALUATOR: llama
EVALUATING: Machine learning es una rama...
RESULT: Respuesta precisa y bien estructurada...

#=== COMBINED RESPONSE 2025-01-21 15:31:00 ===
TYPE: texto_general
COMBINATION: Machine learning es una disciplina...
```

### An√°lisis de Tendencias
```bash
# Contar respuestas por modelo
grep -c "MODEL:" results/complete_history.txt

# Ver evoluci√≥n temporal
grep "EXECUTION" results/complete_history.txt | tail -10
```

## Soluci√≥n de Problemas

### Error: "llama-cli not found"
```bash
# Verificar instalaci√≥n
which llama-cli

# Actualizar configuraci√≥n
vim local-cros.conf
```

### Error: "Model execution failed"
```bash
# Verificar modelo
ls -la /path/to/your/model.gguf

# Probar manualmente
/path/to/llama-cli -m /path/to/model.gguf -p "test"
```

### Respuestas de Baja Calidad
```bash
# Ajustar par√°metros en el script
--temp 0.5        # Menos creatividad, m√°s precisi√≥n
-n 500            # M√°s tokens para respuestas completas
```

## Extensiones y Plugins

### A√±adir Nuevo Modelo
1. Editar `local-cros.conf`
2. A√±adir `MODEL_N_NAME` y `MODEL_N_PATH`
3. Reiniciar script

### Integraci√≥n con APIs Externas
```bash
# Ejemplo: integrar con Claude API para evaluaci√≥n externa
curl -X POST "https://api.anthropic.com/v1/messages" \
  -H "Content-Type: application/json" \
  -d '{"model": "claude-3-sonnet", "messages": [...]}'
```

## Contribuci√≥n

1. Fork del repositorio
2. Crear rama: `git checkout -b feature/nueva-funcionalidad`
3. Commit: `git commit -am 'A√±adir funcionalidad X'`
4. Push: `git push origin feature/nueva-funcionalidad`
5. Pull Request

## Licencia

MIT License

## Autor

**Gustavo Silva da Costa**

## Versi√≥n

**1.0.0** - Sistema de evaluaci√≥n cruzada y s√≠ntesis inteligente

---

*Local-CROS: Donde m√∫ltiples mentes artificiales colaboran para generar respuestas superiores.*
