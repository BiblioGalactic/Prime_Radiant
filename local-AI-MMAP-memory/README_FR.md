M√©moire MMAP IA Locale est un lanceur public en Bash + C con√ßu pour ex√©cuter LLaMA avec plusieurs profils modulaires charg√©s directement en m√©moire via mmap.
Chaque profil repr√©sente un contexte IA distinct (technique, philosophique, s√©curit√©, etc.), permettant de g√©rer les prompts efficacement sans fichiers temporaires.

‚∏ª

üß† Fonctionnalit√©s
	‚Ä¢	Charge plusieurs profils .txt en m√©moire
	‚Ä¢	S√©lection du profil actif √† l‚Äôex√©cution
	‚Ä¢	Ex√©cute LLaMA de fa√ßon interactive avec le contexte charg√© via mmap
	‚Ä¢	Portable et open-source : l‚Äôutilisateur fournit ses propres chemins
	‚Ä¢	Gestion des erreurs pour les fichiers, mmap et le lancement de LLaMA

‚∏ª

‚öôÔ∏è Utilisation

./local-AI-MMAP-memory.sh

Suis les √©tapes pour :
	1.	Entrer ton fichier prompt (.txt)
	2.	Entrer le chemin de l‚Äôex√©cutable llama-cli
	3.	Entrer le chemin de ton mod√®le .gguf
	4.	Entrer les chemins des profils s√©par√©s par des virgules
	5.	Choisir l‚Äôindice du profil actif

‚∏ª

üß© Pr√©requis
	‚Ä¢	Bash ‚â• 5
	‚Ä¢	GCC
	‚Ä¢	LLaMA CLI install√©
	‚Ä¢	Mod√®le local .gguf

‚∏ª

üìú Licence

Open-source ‚Äî Utilise-le librement, modifie-le et partage-le.