本地 AI MMAP 内存

Local AI MMAP Memory 是一个公共的 Bash + C 启动器，用于运行 LLaMA，并通过 mmap 将多个模块化配置文件直接加载到内存中。每个配置文件表示不同的 AI 上下文（技术、哲学、安全等），允许在不使用临时文件的情况下高效管理提示。

⸻

功能
	•	将多个 .txt 配置文件加载到内存中。
	•	运行时选择活跃的配置文件。
	•	通过 mmap 加载上下文，以交互方式运行 LLaMA。
	•	可移植且开源：用户可输入自己的路径。
	•	错误处理：处理文件、mmap 和 LLaMA 启动错误。

⸻

使用方法

./local-AI-MMAP-memory.sh

按照步骤操作：
	1.	输入你的提示文件 (.txt)
	2.	输入 llama-cli 可执行文件路径
	3.	输入你的 .gguf 模型路径
	4.	输入多个配置文件路径，用逗号分隔
	5.	选择活跃配置文件的索引

⸻

系统要求
	•	Bash >= 5
	•	GCC
	•	已安装 LLaMA CLI
	•	本地 .gguf 模型

⸻
