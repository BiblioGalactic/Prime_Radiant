Local AI MMAP Memory Ã©s un llanÃ§ador pÃºblic en Bash + C per executar LLaMA amb mÃºltiples perfils modulars carregats directament a la memÃ²ria mitjanÃ§ant mmap.
Cada perfil representa un context dâ€™IA diferent (tÃ¨cnic, filosÃ²fic, seguretat, etc.), permetent gestionar prompts de manera eficient sense necessitat dâ€™arxius temporals.

â¸»

âš™ï¸ Funcionalitats
	â€¢	Carrega mÃºltiples perfils .txt a la memÃ²ria.
	â€¢	SelecciÃ³ del perfil actiu en temps dâ€™execuciÃ³.
	â€¢	Executa LLaMA de manera interactiva amb el context carregat via mmap.
	â€¢	Portable i de codi obert: lâ€™usuari introdueix les seves prÃ²pies rutes.
	â€¢	GestiÃ³ dâ€™errors per a arxius, mmap i execuciÃ³ de LLaMA.

â¸»

ðŸš€ Ãšs

./local-AI-MMAP-memory.sh

Segueix els passos per a:
	1.	Introduir el teu arxiu prompt (.txt)
	2.	Introduir la ruta a lâ€™executable llama-cli
	3.	Introduir la ruta del teu model .gguf
	4.	Introduir les rutes dels perfils separades per comes
	5.	Escollir lâ€™Ã­ndex del perfil actiu

â¸»

ðŸ§© Requisits
	â€¢	Bash >=5
	â€¢	GCC
	â€¢	LLaMA CLI instalÂ·lat
	â€¢	Model local .gguf

â¸»

ðŸ“„ LlicÃ¨ncia

Codi obert. Utilitzaâ€™l lliurement, modificaâ€™l i comparteix-lo.