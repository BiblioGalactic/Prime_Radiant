# ğŸ¤– MCP Local - Chat IA con Herramientas del Sistema

> **Sistema completo de Model Context Protocol con 11 herramientas y modo agÃ©ntico para tu IA local**

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                            â•‘
â•‘       Transforma tu LLM local en un asistente poderoso     â•‘
â•‘       con acceso a tu sistema operativo                    â•‘
â•‘                                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ“‹ Tabla de Contenidos

- [Â¿QuÃ© es esto?](#-quÃ©-es-esto)
- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [Requisitos](#-requisitos)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [Uso BÃ¡sico](#-uso-bÃ¡sico)
- [Modo AgÃ©ntico](#-modo-agÃ©ntico)
- [Las 11 Herramientas](#-las-11-herramientas)
- [Ejemplos PrÃ¡cticos](#-ejemplos-prÃ¡cticos)
- [ConfiguraciÃ³n Avanzada](#-configuraciÃ³n-avanzada)
- [SoluciÃ³n de Problemas](#-soluciÃ³n-de-problemas)
- [Arquitectura](#-arquitectura)
- [CrÃ©ditos](#-crÃ©ditos)

---

## ğŸ¯ Â¿QuÃ© es esto?

**MCP Local** es un sistema que conecta tu modelo de lenguaje local (como Mistral, Llama, etc.) con **herramientas reales de tu sistema operativo**.

### Sin MCP:
```
ğŸ‘¤ Usuario: "Lista mis archivos Python"
ğŸ¤– IA: "Lo siento, no puedo acceder a tu sistema de archivos"
```

### Con MCP:
```
ğŸ‘¤ Usuario: "Lista mis archivos Python"
ğŸ¤– IA: [BUSCAR] âœ“
       EncontrÃ© 12 archivos: main.py, utils.py, config.py...
```

**Es como darle manos a tu IA para que interactÃºe con tu computadora** ğŸ¦¾

---

## âœ¨ CaracterÃ­sticas

### ğŸ”§ 11 Herramientas Completas
- âœ… Leer y escribir archivos
- âœ… Ejecutar comandos bash
- âœ… Navegar directorios
- âœ… Buscar archivos y contenido
- âœ… Consultar APIs HTTP
- âœ… Descargar archivos desde URLs
- âœ… Comprimir/descomprimir (zip, tar, tar.gz)
- âœ… Operaciones Git (status, log, diff, branch)
- âœ… Monitoreo del sistema (RAM, CPU, disco)
- âœ… BÃºsqueda en contenido (grep)

### ğŸ§  Modo AgÃ©ntico
**Â¡La caracterÃ­stica estrella!** La IA puede encadenar mÃºltiples acciones automÃ¡ticamente:

```
ğŸ‘¤: "descarga el README de GitHub y comprime todos los markdown"

ğŸ¤– [MODO AGÃ‰NTICO]
   ğŸ“‹ Plan: 3 pasos
   ğŸ”„ Descargando... âœ…
   ğŸ”„ Buscando *.md... âœ…  
   ğŸ”„ Comprimiendo... âœ…
   
   âœ… DescarguÃ© el README (3.4KB), encontrÃ© 5 markdown
      y los comprimÃ­ en docs.zip (45KB)
```

### ğŸ”’ Seguridad Integrada
- âŒ Comandos peligrosos bloqueados (rm, dd, sudo, etc.)
- ğŸ›¡ï¸ Solo puede escribir en $HOME o /tmp
- â±ï¸ Timeouts automÃ¡ticos
- ğŸ“¦ LÃ­mites de tamaÃ±o de archivo (10MB)

### ğŸ¨ Interfaz Amigable
- ğŸ’¬ Chat interactivo
- ğŸ“Š Modo verbose para debugging
- ğŸ¯ DetecciÃ³n automÃ¡tica de modo agÃ©ntico
- âš¡ Respuestas rÃ¡pidas y claras

---

## ğŸ“¦ Requisitos

Antes de instalar, asegÃºrate de tener:

### Requisitos Obligatorios
```bash
âœ… Python 3.8 o superior
âœ… pip3
âœ… Un modelo GGUF (Mistral, Llama, etc.)
âœ… llama.cpp compilado con llama-cli
```

### Requisitos Opcionales
```bash
ğŸ”§ git (para herramienta Git)
ğŸ”§ curl/wget (ya incluidos en macOS/Linux)
```

### Sistema Operativo
- âœ… macOS (probado)
- âœ… Linux (probado)
- âš ï¸ Windows (con WSL)

---

## ğŸš€ InstalaciÃ³n

### Paso 1: Descargar el instalador

```bash
# OpciÃ³n A: Clonar el repositorio
git clone https://github.com/tu-repo/mcp-local.git
cd mcp-local

# OpciÃ³n B: Descargar el script directamente
curl -O https://tu-url/mcp_setup.sh
chmod +x mcp_setup.sh
```

### Paso 2: Ejecutar el instalador

```bash
./mcp_setup.sh
```

### Paso 3: Configurar rutas

El instalador te pedirÃ¡ dos rutas:

```
ğŸ¯ CONFIGURACIÃ“N INICIAL
==========================================

ğŸ“ Paso 1/2: Ruta del ejecutable llama-cli
   Ejemplo: /usr/local/bin/llama-cli
   o: /Users/tu-usuario/llama.cpp/build/bin/llama-cli
   Ruta completa: _

ğŸ“ Paso 2/2: Ruta del modelo GGUF
   Ejemplo: /Users/tu-usuario/modelos/mistral-7b-instruct.gguf
   Ruta completa: _
```

### Paso 4: InstalaciÃ³n automÃ¡tica

El script harÃ¡ automÃ¡ticamente:
1. âœ… Crear entorno virtual Python
2. âœ… Instalar dependencias (flask, psutil, requests)
3. âœ… Generar servidor MCP (11 herramientas)
4. âœ… Generar cliente con modo agÃ©ntico
5. âœ… Guardar configuraciÃ³n

```
âœ… INSTALACIÃ“N COMPLETADA

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     MCP LOCAL - MENÃš PRINCIPAL         â•‘
â•‘     ğŸ’ª 11 Herramientas + AgÃ©ntico      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  1) ğŸ’¬ Iniciar chat (con modo agÃ©ntico)
  2) ğŸ”§ Ver herramientas MCP (11)
  3) âš™ï¸  Reconfigurar rutas
  4) ğŸšª Salir
```

---

## ğŸ’¬ Uso BÃ¡sico

### Iniciar el Chat

```bash
./mcp_setup.sh
# Selecciona opciÃ³n 1) Iniciar chat
```

### Comandos del Chat

```
ğŸ‘¤ TÃº: _

Comandos disponibles:
  agentico on/off  â†’ Activar/desactivar modo agÃ©ntico
  verbose on/off   â†’ Ver logs detallados
  herramientas     â†’ Listar las 11 herramientas
  salir            â†’ Cerrar el chat
```

### Ejemplo de ConversaciÃ³n Normal

```bash
ğŸ‘¤ TÃº: lista los archivos de mi escritorio

ğŸ¤– IA: [LISTAR] âœ“
   Tienes 23 items en tu escritorio: Documents/, Downloads/,
   imagen.png, notas.txt...

ğŸ‘¤ TÃº: cuÃ¡nta memoria RAM tengo libre?

ğŸ¤– IA: [MEMORIA] âœ“
   Tienes 8.5GB de RAM disponible de un total de 16GB (53% libre)
```

---

## ğŸ§  Modo AgÃ©ntico

El modo agÃ©ntico permite que la IA **encadene mÃºltiples acciones automÃ¡ticamente** sin que tengas que dar comandos uno por uno.

### Â¿CÃ³mo Activarlo?

**OpciÃ³n 1: Manual**
```bash
ğŸ‘¤ TÃº: agentico on
ğŸ¤– Modo agÃ©ntico: ACTIVADO
```

**OpciÃ³n 2: AutomÃ¡tico** (detecta estas palabras clave)
- `y luego`
- `despuÃ©s`
- `y comprime`
- `y busca`
- `completa todo`
- `haz todo`
- `automÃ¡tico`

### Ejemplo Completo

#### Sin Modo AgÃ©ntico (3 comandos separados):
```bash
ğŸ‘¤: descarga el README
ğŸ¤–: âœ“

ğŸ‘¤: busca todos los markdown
ğŸ¤–: âœ“

ğŸ‘¤: comprime los archivos
ğŸ¤–: âœ“
```

#### Con Modo AgÃ©ntico (1 solo comando):
```bash
ğŸ‘¤: descarga el README de GitHub y luego comprime todos los markdown

ğŸ¤– [MODO AGÃ‰NTICO ACTIVADO]
ğŸ“‹ Plan: 3 pasos

ğŸ”„ Paso 1/3: DESCARGAR:https://raw.githubusercontent.com/...
   âœ… DESCARGAR

ğŸ”„ Paso 2/3: BUSCAR:~/Desktop:*.md
   âœ… BUSCAR

ğŸ”„ Paso 3/3: COMPRIMIR:comprimir:~/Desktop:~/Desktop/docs.zip
   âœ… COMPRIMIR

ğŸ”„ Sintetizando resultados...

âœ… Tarea completada

ğŸ¤– He descargado el README (3456 bytes), encontrado 5 archivos 
   markdown en tu escritorio y los he comprimido en docs.zip 
   (45KB total). Â¡Todo listo!
```

### Modo Verbose (Debug)

Para ver el proceso interno:

```bash
ğŸ‘¤ TÃº: verbose on
ğŸ“Š Modo verbose: ACTIVADO

ğŸ‘¤ TÃº: descarga X y comprime Y

ğŸ§  Planificando pasos...
ğŸ“‹ Pasos planificados: ["DESCARGAR:...", "BUSCAR:...", "COMPRIMIR:..."]
ğŸ” Ejecutando: DESCARGAR:https://...
   âœ… DESCARGAR
ğŸ” Ejecutando: BUSCAR:~/Desktop:*.md
   âœ… BUSCAR
...
```

---

## ğŸ› ï¸ Las 11 Herramientas

### 1. ğŸ“– Leer Archivo
```bash
ğŸ‘¤: lee el archivo README.md
ğŸ¤–: [LEER] âœ“
   El archivo contiene documentaciÃ³n sobre...
```
- ğŸ“¦ MÃ¡ximo: 64KB
- ğŸ”’ Solo archivos de texto

### 2. âœï¸ Escribir Archivo
```bash
ğŸ‘¤: crea un archivo test.txt con "Hola Mundo"
ğŸ¤–: [ESCRIBIR] âœ“ (11 bytes)
   Archivo creado en ~/test.txt
```
- ğŸ“¦ MÃ¡ximo: 10MB
- ğŸ”’ Solo en $HOME o /tmp
- ğŸ”€ Modos: `w` (sobrescribir) o `a` (aÃ±adir)

### 3. ğŸ“ Listar Directorio
```bash
ğŸ‘¤: quÃ© hay en mi carpeta Downloads?
ğŸ¤–: [LISTAR] âœ“
   45 items: documentos/, imagenes/, video.mp4...
```
- ğŸ“Š Muestra: nombre, tipo, tamaÃ±o, fecha
- ğŸ“¦ LÃ­mite: 100 items

### 4. ğŸ” Buscar Archivos
```bash
ğŸ‘¤: encuentra todos mis archivos Python
ğŸ¤–: [BUSCAR] âœ“
   12 archivos encontrados: main.py, utils.py...
```
- ğŸŒ² BÃºsqueda recursiva
- ğŸ¯ Patrones glob: `*.py`, `test*.txt`, etc.
- ğŸ“¦ LÃ­mite: 50 archivos

### 5. ğŸ” Buscar en Contenido (Grep)
```bash
ğŸ‘¤: busca "TODO" en archivos Python
ğŸ¤–: [GREP] âœ“ (8 coincidencias)
   main.py:42: # TODO: Implementar validaciÃ³n
   utils.py:15: # TODO: Optimizar algoritmo
```
- ğŸ“„ Solo archivos <1MB
- ğŸ¯ Regex case-insensitive
- ğŸ“¦ LÃ­mite: 50 coincidencias

### 6. âš¡ Ejecutar Comando
```bash
ğŸ‘¤: ejecuta ls -la
ğŸ¤–: [COMANDO] âœ“
   total 256
   drwxr-xr-x  15 user  staff   480 Oct 10 10:30 .
   ...
```
- âŒ **Bloqueados**: rm, dd, sudo, su, mkfs
- â±ï¸ Timeout: 10 segundos
- ğŸ“¦ Output: 4KB mÃ¡ximo

### 7. ğŸ’¾ Consultar Memoria
```bash
ğŸ‘¤: cuÃ¡ntos recursos tengo disponibles?
ğŸ¤–: [MEMORIA] âœ“
   RAM: 8.5GB libre de 16GB
   CPU: 35% de uso (8 cores)
   Disco: 245GB libres de 500GB
```

### 8. ğŸ“¥ Descargar Archivo
```bash
ğŸ‘¤: descarga https://example.com/file.pdf
ğŸ¤–: [DESCARGAR] âœ“ (2.5MB)
   Archivo guardado en ~/Downloads/file.pdf
```
- ğŸŒ Solo http:// y https://
- ğŸ“¦ LÃ­mite: 10MB
- â±ï¸ Timeout: 30 segundos

### 9. ğŸ—œï¸ Comprimir/Descomprimir
```bash
ğŸ‘¤: comprime mi carpeta documentos
ğŸ¤–: [COMPRIMIR] âœ“
   Carpeta comprimida en documentos.zip (12MB)
```
- ğŸ“¦ Formatos: zip, tar, tar.gz
- ğŸ”„ Operaciones: comprimir, descomprimir

### 10. ğŸ”§ Git Operations
```bash
ğŸ‘¤: muestra el status de git
ğŸ¤–: [GIT] âœ“
   On branch main
   Changes not staged for commit:
     modified: src/main.py
```
- âœ… Permitidos: status, log, diff, branch, remote
- âŒ **Bloqueados**: commit, push, pull (solo lectura)

### 11. ğŸŒ Consultar API
```bash
ğŸ‘¤: consulta la API de ejemplo.com
ğŸ¤–: [API] âœ“ (200)
   Status: OK
   Respuesta: {"data": "ejemplo"}
```
- ğŸ“¡ MÃ©todos: GET, POST, PUT, DELETE, PATCH
- â±ï¸ Timeout: 10 segundos
- ğŸ“¦ Respuesta: 4KB mÃ¡ximo

---

## ğŸ’¡ Ejemplos PrÃ¡cticos

### Ejemplo 1: AnÃ¡lisis de Proyecto
```bash
ğŸ‘¤: agentico on

ğŸ‘¤: lista todos los archivos Python y busca TODOs pendientes

ğŸ¤– [MODO AGÃ‰NTICO]
   Paso 1: Buscando *.py... âœ…
   Paso 2: Buscando 'TODO'... âœ…
   
   EncontrÃ© 12 archivos Python con 8 TODOs pendientes:
   - main.py: 3 TODOs
   - utils.py: 2 TODOs
   - config.py: 3 TODOs
```

### Ejemplo 2: Backup Automatizado
```bash
ğŸ‘¤: busca todos los archivos importantes y comprimelos en un backup

ğŸ¤– [MODO AGÃ‰NTICO]
   Paso 1: Buscando archivos... âœ…
   Paso 2: Comprimiendo... âœ…
   
   He creado backup.zip con 45 archivos (234MB total)
```

### Ejemplo 3: Monitoreo de Sistema
```bash
ğŸ‘¤: muestra el estado de git y los recursos del sistema

ğŸ¤– [MODO AGÃ‰NTICO]
   Paso 1: Git status... âœ…
   Paso 2: Consultando recursos... âœ…
   
   Git: 3 archivos modificados en rama main
   Sistema: RAM 45% libre, CPU 25%, Disco 50% libre
```

### Ejemplo 4: Workflow Completo
```bash
ğŸ‘¤: descarga el README de GitHub, bÃºscalo en mi escritorio 
    y comprime todos los markdown que encuentres

ğŸ¤– [MODO AGÃ‰NTICO]
   ğŸ“‹ Plan: 3 pasos
   
   Paso 1: Descargando desde GitHub... âœ… (3.4KB)
   Paso 2: Buscando *.md en Desktop... âœ… (5 archivos)
   Paso 3: Comprimiendo archivos... âœ… (45KB)
   
   âœ… DescarguÃ© el README, encontrÃ© 5 markdown y los 
      comprimÃ­ en docs.zip. Todo estÃ¡ en tu escritorio.
```

---

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Cambiar Modelo o Ruta de llama-cli

```bash
./mcp_setup.sh
# Selecciona opciÃ³n 3) Reconfigurar rutas
```

### Editar ConfiguraciÃ³n Manual

```bash
nano ~/.mcp_local/config.env
```

```bash
# ConfiguraciÃ³n MCP Local
LLAMA_CLI="/ruta/a/tu/llama-cli"
MODELO_GGUF="/ruta/a/tu/modelo.gguf"
```

### Variables de Entorno

```bash
# Activar debug del servidor MCP
export MCP_DEBUG=1

# Ejecutar
./mcp_setup.sh
```

### Estructura de Archivos

```
~/.mcp_local/
â”œâ”€â”€ config.env           # Tu configuraciÃ³n
â”œâ”€â”€ venv/                # Entorno Python
â”œâ”€â”€ mcp_server.py        # Servidor con 11 herramientas
â””â”€â”€ chat_mcp.py          # Cliente con modo agÃ©ntico
```

---

## ğŸ”§ SoluciÃ³n de Problemas

### Problema: "llama-cli no encontrado"

**SoluciÃ³n:**
```bash
# Verificar que llama.cpp estÃ© compilado
cd ~/llama.cpp
cmake -B build
cmake --build build

# Verificar ruta
ls ~/llama.cpp/build/bin/llama-cli

# Reconfigurar MCP
./mcp_setup.sh
# OpciÃ³n 3) Reconfigurar rutas
```

### Problema: "Modelo no encontrado"

**SoluciÃ³n:**
```bash
# Verificar que el modelo existe
ls ~/ruta/a/tu/modelo.gguf

# Si no tienes modelo, descarga uno
# Ejemplo: Mistral 7B
wget https://huggingface.co/...modelo.gguf

# Reconfigurar
./mcp_setup.sh
# OpciÃ³n 3) Reconfigurar rutas
```

### Problema: "Error instalando dependencias Python"

**SoluciÃ³n:**
```bash
# Verificar Python
python3 --version  # Debe ser 3.8+

# Limpiar entorno virtual
rm -rf ~/.mcp_local/venv

# Reinstalar
./mcp_setup.sh
```

### Problema: "Modo agÃ©ntico no funciona bien"

**SoluciÃ³n:**
```bash
# Usar modo verbose para ver quÃ© pasa
ğŸ‘¤: verbose on
ğŸ‘¤: tu comando problemÃ¡tico

# El modo agÃ©ntico depende de la calidad del modelo
# Modelos recomendados:
# - Mistral 7B Instruct (mÃ­nimo)
# - Llama 3 8B Instruct (mejor)
# - Mixtral 8x7B (Ã³ptimo)
```

### Problema: "Timeout en consultas"

**SoluciÃ³n:**
```bash
# Si el modelo es muy lento, aumentar timeout
# Editar ~/.mcp_local/chat_mcp.py

# LÃ­nea ~40:
IA_CMD = [
    config.get('LLAMA_CLI', 'llama-cli'),
    "--model", config.get('MODELO_GGUF', ''),
    "--n-predict", "512",
    "--temp", "0.7",
    "--ctx-size", "4096"
]

# Agregar GPU si estÃ¡ disponible:
# "--n-gpu-layers", "35"
```

### Problema: "Comando bloqueado por seguridad"

**SoluciÃ³n:**
Esto es intencional. Comandos peligrosos estÃ¡n bloqueados:
- âŒ `rm -rf`
- âŒ `dd`
- âŒ `sudo`
- âŒ `su`

Si realmente necesitas ejecutar comandos privilegiados, hazlo manualmente fuera del MCP.

---

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ğŸ‘¤ Usuario (TÃš)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      ğŸ’¬ Cliente Chat (chat_mcp.py)          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  ğŸ§  Modo AgÃ©ntico                  â”‚     â”‚
â”‚  â”‚  - PlanificaciÃ³n de pasos          â”‚     â”‚
â”‚  â”‚  - EjecuciÃ³n secuencial            â”‚     â”‚
â”‚  â”‚  - SÃ­ntesis de resultados          â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        ğŸ¤– Modelo LLM Local                  â”‚
â”‚     (Mistral, Llama, Mixtral, etc.)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ğŸ”§ Servidor MCP (mcp_server.py)           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  11 Herramientas:                  â”‚     â”‚
â”‚  â”‚  âœ“ Archivos (leer/escribir)        â”‚     â”‚
â”‚  â”‚  âœ“ Sistema (memoria/comandos)      â”‚     â”‚
â”‚  â”‚  âœ“ Red (API/descargas)             â”‚     â”‚
â”‚  â”‚  âœ“ BÃºsqueda (archivos/contenido)   â”‚     â”‚
â”‚  â”‚  âœ“ Utilidades (git/comprimir)      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     ğŸ’» Tu Sistema Operativo                 â”‚
â”‚  (Archivos, Comandos, Recursos)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de una Consulta Normal

```
1. Usuario escribe comando
   ğŸ‘¤ "lista archivos Python"
   
2. Cliente consulta al LLM
   ğŸ’¬ â†’ ğŸ¤– "Â¿QuÃ© herramienta usar?"
   
3. LLM decide herramienta
   ğŸ¤– â†’ ğŸ’¬ "[USAR_HERRAMIENTA:BUSCAR:.:*.py]"
   
4. Cliente llama al servidor MCP
   ğŸ’¬ â†’ ğŸ”§ {"method": "buscar_archivos", ...}
   
5. Servidor ejecuta herramienta
   ğŸ”§ â†’ ğŸ’» BÃºsqueda real en el sistema
   
6. Servidor devuelve resultados
   ğŸ”§ â†’ ğŸ’¬ {"result": ["main.py", ...]}
   
7. Cliente envÃ­a resultados al LLM
   ğŸ’¬ â†’ ğŸ¤– "Archivos encontrados: ..."
   
8. LLM genera respuesta natural
   ğŸ¤– â†’ ğŸ’¬ "EncontrÃ© 12 archivos Python: ..."
   
9. Usuario ve la respuesta
   ğŸ’¬ â†’ ğŸ‘¤ "EncontrÃ© 12 archivos Python: ..."
```

### Flujo del Modo AgÃ©ntico

```
1. Usuario da comando complejo
   ğŸ‘¤ "descarga X y luego comprime Y"
   
2. Cliente detecta modo agÃ©ntico
   ğŸ’¬ [Detecta palabras clave "y luego"]
   
3. LLM planifica pasos
   ğŸ’¬ â†’ ğŸ¤– "DescompÃ³n en pasos"
   ğŸ¤– â†’ ğŸ’¬ ["DESCARGAR:...", "BUSCAR:...", "COMPRIMIR:..."]
   
4. Cliente ejecuta pasos secuencialmente
   ğŸ’¬ â†’ ğŸ”§ Paso 1: DESCARGAR âœ…
   ğŸ’¬ â†’ ğŸ”§ Paso 2: BUSCAR âœ…
   ğŸ’¬ â†’ ğŸ”§ Paso 3: COMPRIMIR âœ…
   
5. LLM sintetiza resultados
   ğŸ’¬ â†’ ğŸ¤– "Resume todo lo hecho"
   ğŸ¤– â†’ ğŸ’¬ "DescarguÃ©, busquÃ© y comprimÃ­..."
   
6. Usuario ve resumen final
   ğŸ’¬ â†’ ğŸ‘¤ "âœ… Tarea completada: ..."
```

---

## ğŸ“š Recursos Adicionales

### Model Context Protocol (MCP)
- ğŸ“– [EspecificaciÃ³n MCP](https://spec.modelcontextprotocol.io/)
- ğŸ”— [GitHub de Anthropic MCP](https://github.com/anthropics/mcp)

### Modelos Recomendados
- ğŸ¦™ [Llama 3 8B Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)
- ğŸŒŸ [Mistral 7B Instruct](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1)
- ğŸš€ [Mixtral 8x7B](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)

### llama.cpp
- ğŸ”— [GitHub llama.cpp](https://github.com/ggerganov/llama.cpp)
- ğŸ“– [DocumentaciÃ³n](https://github.com/ggerganov/llama.cpp/blob/master/README.md)

---

## ğŸ“ Casos de Uso

### Para Desarrolladores
- âœ… Automatizar tareas repetitivas
- âœ… Analizar cÃ³digo y buscar TODOs
- âœ… Gestionar repositorios Git
- âœ… Generar documentaciÃ³n
- âœ… Monitorear recursos del sistema

### Para Administradores de Sistemas
- âœ… Automatizar backups
- âœ… Monitorear logs
- âœ… Gestionar archivos de configuraciÃ³n
- âœ… Buscar informaciÃ³n en logs
- âœ… Comprimir/descomprimir archivos

### Para Usuarios Avanzados
- âœ… Organizar archivos automÃ¡ticamente
- âœ… Descargar y procesar contenido web
- âœ… Buscar informaciÃ³n en documentos
- âœ… Automatizar workflows complejos
- âœ… Integrar con APIs externas

---

## ğŸ¤ Contribuir

Â¿Tienes ideas para mejorar MCP Local? Â¡Contribuye!

### Ideas de Nuevas Herramientas
- ğŸ“§ Cliente de email
- ğŸ“… IntegraciÃ³n con calendario
- ğŸ—„ï¸ Operaciones con bases de datos
- ğŸ³ IntegraciÃ³n con Docker
- ğŸ“Š GeneraciÃ³n de reportes

### CÃ³mo Contribuir
1. Fork el proyecto
2. Crea una rama (`git checkout -b feature/nueva-herramienta`)
3. Commit tus cambios (`git commit -am 'AÃ±ade nueva herramienta X'`)
4. Push a la rama (`git push origin feature/nueva-herramienta`)
5. Abre un Pull Request

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ãšsalo libremente, modifÃ­calo y compÃ¡rtelo.

```
MIT License

Copyright (c) 2025 Gustavo Silva Da Costa

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---

## ğŸ™ Agradecimientos

- Anthropic por el concepto de Model Context Protocol
- Comunidad de llama.cpp por hacer posible ejecutar LLMs localmente
- Todos los que contribuyen al ecosistema de IA open source

---

## ğŸ“ Soporte

Â¿Problemas? Â¿Preguntas? Â¿Sugerencias?

- ğŸ“§ Email: gsilvadacosta0@gmail.com 
- ğŸ†‡ Antiguo twitter ğŸ˜‚: https://x.com/bibliogalactic

---

<div align="center">

## â­ Si te gusta este proyecto, dale una estrella en GitHub â­

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                        â•‘
â•‘   Hecho con â¤ï¸ para la comunidad de IA local          â•‘
â•‘                                                        â•‘
â•‘   "Dando manos a las IAs, una herramienta a la vez"   â•‘
â•‘                                                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### ğŸ‘¨â€ğŸ’» Creado por

**Gustavo Silva Da Costa** (Eto Demerzel) ğŸ¤«

ğŸš€ *Transformando IAs locales en asistentes poderosos*

</div>

---

**VersiÃ³n:** 1.0.0  
**Ãšltima actualizaciÃ³n:** Octubre 2025  
**Estado:** âœ… ProducciÃ³n

---
