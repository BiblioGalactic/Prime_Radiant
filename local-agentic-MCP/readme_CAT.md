# ğŸ¤– MCP Local - Xat IA amb Eines de Sistema

> **Sistema complet de Model Context Protocol amb 11 eines i mode agent (per a IA local)**

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                            â•‘
â•‘       Transforma el teu LLM local en un assistent potent  â•‘
â•‘       amb accÃ©s al sistema operatiu                        â•‘
â•‘                                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ“‹ Ãndex

- [QuÃ¨ Ã©s aixÃ²?](#-quÃ¨-Ã©s-aixÃ²)
- [CaracterÃ­stiques](#-caracterÃ­stiques)
- [Requisits](#-requisits)
- [InstalÂ·laciÃ³](#-installaciÃ³)
- [Ãšs bÃ sic](#-Ãºs-bÃ sic)
- [Mode Agent](#-mode-agent)
- [Les 11 eines](#-les-11-eines)
- [Exemples prÃ ctics](#-exemples-prÃ ctics)
- [ConfiguraciÃ³ avanÃ§ada](#-configuraciÃ³-avanÃ§ada)
- [ResoluciÃ³ de problemes](#-resoluciÃ³-de-problemes)
- [Arquitectura](#-arquitectura)
- [CrÃ¨dits](#-crÃ¨dits)

---

## ğŸ¯ QuÃ¨ Ã©s aixÃ²?

**MCP Local** Ã©s un sistema que connecta els teus models de llenguatge locals (Mistral, Llama, etc.) amb **eines reals del sistema operatiu**.

### Sense MCP:
```
ğŸ‘¤ Usuari: "Llista'm els fitxers Python"
ğŸ¤– IA: "Ho sento, no puc accedir al sistema de fitxers"
```

### Amb MCP:
```
ğŸ‘¤ Usuari: "Llista'm els fitxers Python"
ğŸ¤– IA: [Cerca] âœ“
       He trobat 12 fitxers: main.py, utils.py, config.py...
```

**Ã‰s com donar mans a la IA per interactuar amb el teu ordinador** ğŸ¦¾

---

## âœ¨ CaracterÃ­stiques

### ğŸ”§ 11 Eines Completes
- âœ… Llegir i escriure fitxers
- âœ… Executar comandes bash
- âœ… Navegar per directoris
- âœ… Cercar fitxers i contingut
- âœ… Consultar APIs HTTP
- âœ… Descarregar fitxers des d'URLs
- âœ… Comprimir/descomprimir (zip, tar, tar.gz)
- âœ… Operacions Git (status, log, diff, branch)
- âœ… Monitoritzar sistema (RAM, CPU, disc)
- âœ… Cercar contingut (grep)

### ğŸ§  Mode Agent
**Funcionalitat estrella!** La IA pot encadenar mÃºltiples accions automÃ ticament:

```
ğŸ‘¤: "Descarrega el README de GitHub i comprimeix tots els fitxers markdown"

ğŸ¤– [Mode Agent]
   ğŸ“‹ Pla: 3 passos
   ğŸ”„ Descarregant... âœ…
   ğŸ”„ Cercant *.md... âœ…  
   ğŸ”„ Comprimint... âœ…
   
   âœ… He descarregat el README (3.4KB), he trobat 5 fitxers markdown
      i els he comprimit a docs.zip (45KB)
```

### ğŸ”’ Seguretat Integrada
- âŒ Bloqueja comandes perilloses (rm, dd, sudo, etc.)
- ğŸ›¡ï¸ NomÃ©s permet escriure a $HOME o /tmp
- â±ï¸ Timeout automÃ tic
- ğŸ“¦ LÃ­mit de mida de fitxers (10MB)

### ğŸ¨ InterfÃ­cie FÃ cil d'Usar
- ğŸ’¬ Xat interactiu
- ğŸ“Š Mode verbose per a depuraciÃ³
- ğŸ¯ DetecciÃ³ automÃ tica de mode agent
- âš¡ Respostes rÃ pides i clares

---

## ğŸ“¦ Requisits

Abans d'instalÂ·lar, assegura't de tenir:

### Requisits Obligatoris
```bash
âœ… Python 3.8 o superior
âœ… pip3
âœ… Model GGUF (Mistral, Llama, etc.)
âœ… llama.cpp compilat amb llama-cli
```

### Requisits Opcionals
```bash
ğŸ”§ git (per a eines Git)
ğŸ”§ curl/wget (inclÃ²s a macOS/Linux)
```

### Sistemes Operatius
- âœ… macOS (provat)
- âœ… Linux (provat)
- âš ï¸ Windows (amb WSL)

---

## ğŸš€ InstalÂ·laciÃ³

### Pas 1: Descarregar l'InstalÂ·lador

```bash
# OpciÃ³ A: Clonar el repositori
git clone https://github.com/your-repo/mcp-local.git
cd mcp-local

# OpciÃ³ B: Descarregar l'script directament
curl -O https://your-url/mcp_setup.sh
chmod +x mcp_setup.sh
```

### Pas 2: Executar l'InstalÂ·lador

```bash
./mcp_setup.sh
```

### Pas 3: Configurar les Rutes

L'instalÂ·lador et demanarÃ  dues rutes:

```
ğŸ¯ ConfiguraciÃ³ Inicial
==========================================

ğŸ“ Pas 1/2: Ruta a l'executable llama-cli
   Exemple: /usr/local/bin/llama-cli
   O: /Users/el-teu-usuari/llama.cpp/build/bin/llama-cli
   Ruta completa: _

ğŸ“ Pas 2/2: Ruta al model GGUF
   Exemple: /Users/el-teu-usuari/models/mistral-7b-instruct.gguf
   Ruta completa: _
```

### Pas 4: InstalÂ·laciÃ³ AutomÃ tica

L'script automÃ ticament:
1. âœ… Crea l'entorn virtual Python
2. âœ… InstalÂ·la dependÃ¨ncies (flask, psutil, requests)
3. âœ… Genera el servidor MCP (11 eines)
4. âœ… Genera el client amb mode agent
5. âœ… Desa la configuraciÃ³

```
âœ… InstalÂ·laciÃ³ Completa

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     MCP LOCAL - MenÃº Principal         â•‘
â•‘     ğŸ’ª 11 Eines + Agent                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  1) ğŸ’¬ Iniciar xat (amb mode agent)
  2) ğŸ”§ Mostrar eines MCP (11)
  3) âš™ï¸  Reconfigurar rutes
  4) ğŸšª Sortir
```

---

## ğŸ’¬ Ãšs BÃ sic

### Iniciar el Xat

```bash
./mcp_setup.sh
# Selecciona opciÃ³ 1) Iniciar xat
```

### Comandes del Xat

```
ğŸ‘¤ Tu: _

Comandes disponibles:
  agentic on/off  â†’ Activa/desactiva el mode agent
  verbose on/off  â†’ Mostra logs detallats
  herramientas    â†’ Llista les 11 eines
  salir           â†’ Tanca el xat
```

### Exemple de Conversa Normal

```bash
ğŸ‘¤ Tu: Llista els fitxers de l'escriptori

ğŸ¤– IA: [Llistat] âœ“
   Hi ha 23 elements a l'escriptori: Documents/, Downloads/,
   imatge.png, notes.txt...

ğŸ‘¤ Tu: Quanta RAM tinc lliure?

ğŸ¤– IA: [MemÃ²ria] âœ“
   Tens 8.5GB de RAM lliure de 16GB totals (53% lliure)
```

---

## ğŸ§  Mode Agent

El mode agent permet que la IA **encadeni mÃºltiples accions automÃ ticament**, sense necessitat de donar comandes una per una.

### Com Activar-lo

**OpciÃ³ 1: Manual**
```bash
ğŸ‘¤ Tu: agentic on
ğŸ¤– Mode Agent: Activat
```

**OpciÃ³ 2: AutomÃ tic** (detecta aquestes paraules clau)
- `i`
- `desprÃ©s`
- `i comprimeix`
- `i cerca`
- `fes-ho tot`
- `executa tot`
- `automÃ tic`

### Exemple Complet

#### Sense Mode Agent (3 comandes separades):
```bash
ğŸ‘¤: Descarrega el README
ğŸ¤–: âœ“

ğŸ‘¤: Cerca tots els fitxers markdown
ğŸ¤–: âœ“

ğŸ‘¤: Comprimeix els fitxers
ğŸ¤–: âœ“
```

#### Amb Mode Agent (1 sola comanda):
```bash
ğŸ‘¤: Descarrega el README de GitHub i desprÃ©s comprimeix tots els fitxers markdown

ğŸ¤– [Mode Agent Activat]
ğŸ“‹ Pla: 3 passos

ğŸ”„ Pas 1/3: Descarregant https://raw.githubusercontent.com/...
   âœ… Descarregat

ğŸ”„ Pas 2/3: Cercant ~/Desktop:*.md
   âœ… Trobat

ğŸ”„ Pas 3/3: Comprimint ~/Desktop a ~/Desktop/docs.zip
   âœ… Comprimit

ğŸ”„ Integrant resultats...

âœ… Tasca Completada

ğŸ¤– He descarregat el README (3456 bytes), he trobat 5 fitxers
   markdown a l'escriptori i els he comprimit a docs.zip
   (45KB total). Fet!
```

### Mode Verbose (DepuraciÃ³)

Per veure el procÃ©s intern:

```bash
ğŸ‘¤ Tu: verbose on
ğŸ“Š Mode Verbose: Activat

ğŸ‘¤ Tu: Descarrega X i comprimeix Y

ğŸ§  Planejant passos...
ğŸ“‹ Passos planificats: ["download:...", "search:...", "compress:..."]
ğŸ” Executant: download:https://...
   âœ… Descarregat
ğŸ” Executant: search:~/Desktop:*.md
   âœ… Trobat
...
```

---

## ğŸ› ï¸ Les 11 Eines

### 1. ğŸ“– Llegir Fitxer
```bash
ğŸ‘¤: Llegeix el fitxer README.md
ğŸ¤–: [Lectura] âœ“
   El fitxer contÃ© documentaciÃ³ sobre...
```
- ğŸ“¦ MÃ xim: 64KB
- ğŸ”’ NomÃ©s fitxers de text

### 2. âœï¸ Escriure Fitxer
```bash
ğŸ‘¤: Crea un fitxer test.txt amb "Hola MÃ³n"
ğŸ¤–: [Escriptura] âœ“ (11 bytes)
   Fitxer creat a ~/test.txt
```
- ğŸ“¦ MÃ xim: 10MB
- ğŸ”’ NomÃ©s a $HOME o /tmp
- ğŸ”€ Modes: `w` (sobreescriu) o `a` (afegeix)

### 3. ğŸ“ Llistar Directori
```bash
ğŸ‘¤: QuÃ¨ hi ha a la carpeta Downloads?
ğŸ¤–: [Llistat] âœ“
   45 elements: documents/, images/, video.mp4...
```
- ğŸ“Š Mostra: nom, tipus, mida, data
- ğŸ“¦ LÃ­mit: 100 elements

### 4. ğŸ” Cercar Fitxers
```bash
ğŸ‘¤: Troba tots els fitxers Python
ğŸ¤–: [Cerca] âœ“
   He trobat 12 fitxers: main.py, utils.py...
```
- ğŸŒ² Cerca recursiva
- ğŸ¯ Patrons Glob: `*.py`, `test*.txt`, etc.
- ğŸ“¦ LÃ­mit: 50 fitxers

### 5. ğŸ” Cercar Contingut (Grep)
```bash
ğŸ‘¤: Cerca "TODO" als fitxers Python
ğŸ¤–: [GREP] âœ“ (8 coincidÃ¨ncies)
   main.py:42: # TODO: implementar validaciÃ³
   utils.py:15: # TODO: optimitzar algorisme
```
- ğŸ“„ NomÃ©s fitxers < 1MB
- ğŸ¯ Regex insensible a majÃºscules
- ğŸ“¦ LÃ­mit: 50 coincidÃ¨ncies

### 6. âš¡ Executar Comanda
```bash
ğŸ‘¤: Executa ls -la
ğŸ¤–: [Comanda] âœ“
   total 256
   drwxr-xr-x  15 user  staff   480 Oct 10 10:30 .
   ...
```
- âŒ **Bloquejades**: rm, dd, sudo, su, mkfs
- â±ï¸ Timeout: 10 segons
- ğŸ“¦ Sortida: mÃ xim 4KB

### 7. ğŸ’¾ Consultar MemÃ²ria
```bash
ğŸ‘¤: Quants recursos tinc disponibles?
ğŸ¤–: [MemÃ²ria] âœ“
   RAM: 8.5GB lliure de 16GB
   CPU: 35% en Ãºs (8 nuclis)
   Disc: 245GB lliure de 500GB
```

### 8. ğŸ“¥ Descarregar Fitxer
```bash
ğŸ‘¤: Descarrega https://example.com/file.pdf
ğŸ¤–: [DescÃ rrega] âœ“ (2.5MB)
   Fitxer desat a ~/Downloads/file.pdf
```
- ğŸŒ NomÃ©s http:// i https://
- ğŸ“¦ LÃ­mit: 10MB
- â±ï¸ Timeout: 30 segons

### 9. ğŸ—œï¸ Comprimir/Descomprimir
```bash
ğŸ‘¤: Comprimeix la carpeta documents
ğŸ¤–: [CompressiÃ³] âœ“
   Carpeta comprimida a documents.zip (12MB)
```
- ğŸ“¦ Formats: zip, tar, tar.gz
- ğŸ”„ Operacions: comprimir, descomprimir

### 10. ğŸ”§ Operacions Git
```bash
ğŸ‘¤: Mostra l'estat de git
ğŸ¤–: [GIT] âœ“
   On branch main
   Changes not staged for commit:
     modified: src/main.py
```
- âœ… Permeses: status, log, diff, branch, remote
- âŒ **Bloquejades**: commit, push, pull (nomÃ©s lectura)

### 11. ğŸŒ Consultar API
```bash
ğŸ‘¤: Consulta l'API d'example.com
ğŸ¤–: [API] âœ“ (200)
   Estat: OK
   Resposta: {"data": "exemple"}
```
- ğŸ“¡ MÃ¨todes: GET, POST, PUT, DELETE, PATCH
- â±ï¸ Timeout: 10 segons
- ğŸ“¦ Resposta: mÃ xim 4KB

---

## ğŸ’¡ Exemples PrÃ ctics

### Exemple 1: AnÃ lisi de Projecte
```bash
ğŸ‘¤: agentic on

ğŸ‘¤: Llista tots els fitxers Python i cerca els TODOs pendents

ğŸ¤– [Mode Agent]
   Pas 1: Cercant *.py... âœ…
   Pas 2: Cercant 'TODO'... âœ…
   
   He trobat 12 fitxers Python amb 8 TODOs pendents:
   - main.py: 3 TODOs
   - utils.py: 2 TODOs
   - config.py: 3 TODOs
```

### Exemple 2: CÃ²pia de Seguretat AutomÃ tica
```bash
ğŸ‘¤: Cerca tots els fitxers importants i comprimeix-los a backup

ğŸ¤– [Mode Agent]
   Pas 1: Cercant fitxers... âœ…
   Pas 2: Comprimint... âœ…
   
   He creat backup.zip amb 45 fitxers (234MB total)
```

### Exemple 3: MonitoritzaciÃ³ de Sistema
```bash
ğŸ‘¤: Mostra l'estat de git i els recursos del sistema

ğŸ¤– [Mode Agent]
   Pas 1: Estat Git... âœ…
   Pas 2: Consultant recursos... âœ…
   
   Git: 3 fitxers modificats a la branca main
   Sistema: RAM 45% lliure, CPU 25%, Disc 50% lliure
```

### Exemple 4: Flux de Treball Complet
```bash
ğŸ‘¤: Descarrega el README de GitHub, cerca'l a l'escriptori
    i comprimeix tots els fitxers markdown que trobis

ğŸ¤– [Mode Agent]
   ğŸ“‹ Pla: 3 passos
   
   Pas 1: Descarregant de GitHub... âœ… (3.4KB)
   Pas 2: Cercant *.md a l'escriptori... âœ… (5 fitxers)
   Pas 3: Comprimint fitxers... âœ… (45KB)
   
   âœ… He descarregat el README, he trobat 5 fitxers markdown
      i els he comprimit a docs.zip. Tot a l'escriptori.
```

---

## âš™ï¸ ConfiguraciÃ³ AvanÃ§ada

### Canviar Model o Ruta llama-cli

```bash
./mcp_setup.sh
# Selecciona opciÃ³ 3) Reconfigurar rutes
```

### Editar ConfiguraciÃ³ Manualment

```bash
nano ~/.mcp_local/config.env
```

```bash
# ConfiguraciÃ³ MCP Local
LLAMA_CLI="/ruta/al/teu/llama-cli"
MODELO_GGUF="/ruta/al/teu/model.gguf"
```

### Variables d'Entorn

```bash
# Activar depuraciÃ³ del servidor MCP
export MCP_DEBUG=1

# Executar
./mcp_setup.sh
```

### Estructura de Fitxers

```
~/.mcp_local/
â”œâ”€â”€ config.env           # La teva configuraciÃ³
â”œâ”€â”€ venv/                # Entorn Python
â”œâ”€â”€ mcp_server.py        # Servidor amb 11 eines
â””â”€â”€ chat_mcp.py          # Client amb mode agent
```

---

## ğŸ”§ ResoluciÃ³ de Problemes

### Problema: "No es troba llama-cli"

**SoluciÃ³:**
```bash
# Verifica que llama.cpp estigui compilat
cd ~/llama.cpp
cmake -B build
cmake --build build

# Verifica la ruta
ls ~/llama.cpp/build/bin/llama-cli

# Reconfigura MCP
./mcp_setup.sh
# OpciÃ³ 3) Reconfigurar rutes
```

### Problema: "No es troba el model"

**SoluciÃ³:**
```bash
# Verifica que el model existeixi
ls ~/ruta/al/teu/model.gguf

# Si no tens model, descarrega'n un
# Exemple: Mistral 7B
wget https://huggingface.co/...model.gguf

# Reconfigura
./mcp_setup.sh
# OpciÃ³ 3) Reconfigurar rutes
```

### Problema: "Error instalÂ·lant dependÃ¨ncies Python"

**SoluciÃ³:**
```bash
# Verifica Python
python3 --version  # Ha de ser 3.8+

# Neteja l'entorn virtual
rm -rf ~/.mcp_local/venv

# ReinstalÂ·la
./mcp_setup.sh
```

### Problema: "El mode agent no funciona bÃ©"

**SoluciÃ³:**
```bash
# Utilitza el mode verbose per veure quÃ¨ passa
ğŸ‘¤: verbose on
ğŸ‘¤: la comanda problemÃ tica

# El mode agent depÃ¨n de la qualitat del model
# Models recomanats:
# - Mistral 7B Instruct (mÃ­nim)
# - Llama 3 8B Instruct (millor)
# - Mixtral 8x7B (Ã²ptim)
```

### Problema: "Timeout en consultes"

**SoluciÃ³:**
```bash
# Si el model Ã©s molt lent, augmenta el timeout
# Edita ~/.mcp_local/chat_mcp.py

# A la lÃ­nia ~40:
IA_CMD = [
    config.get('LLAMA_CLI', 'llama-cli'),
    "--model", config.get('MODELO_GGUF', ''),
    "--n-predict", "512",
    "--temp", "0.7",
    "--ctx-size", "4096"
]

# Si tens GPU disponible, afegeix:
# "--n-gpu-layers", "35"
```

### Problema: "Comanda bloquejada per seguretat"

**SoluciÃ³:**
AixÃ² Ã©s intencional. Les comandes perilloses estan bloquejades:
- âŒ `rm -rf`
- âŒ `dd`
- âŒ `sudo`
- âŒ `su`

Si necessites executar comandes privilegiades, fes-ho manualment fora de MCP.

---

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ğŸ‘¤ Usuari (tu)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      ğŸ’¬ Client Xat (chat_mcp.py)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  ğŸ§  Mode Agent                     â”‚     â”‚
â”‚  â”‚  - PlanificaciÃ³ de passos          â”‚     â”‚
â”‚  â”‚  - ExecuciÃ³ seqÃ¼encial             â”‚     â”‚
â”‚  â”‚  - IntegraciÃ³ de resultats         â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        ğŸ¤– Model LLM Local                   â”‚
â”‚     (Mistral, Llama, Mixtral, etc.)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ğŸ”§ Servidor MCP (mcp_server.py)           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  11 eines:                         â”‚     â”‚
â”‚  â”‚  âœ“ Fitxers (llegir/escriure)       â”‚     â”‚
â”‚  â”‚  âœ“ Sistema (memÃ²ria/comandes)      â”‚     â”‚
â”‚  â”‚  âœ“ Xarxa (API/descÃ rregues)        â”‚     â”‚
â”‚  â”‚  âœ“ Cerca (fitxers/contingut)       â”‚     â”‚
â”‚  â”‚  âœ“ Utilitats (git/compressiÃ³)      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     ğŸ’» El teu Sistema Operatiu              â”‚
â”‚  (fitxers, comandes, recursos)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flux de Consulta Normal

```
1. L'usuari introdueix una comanda
   ğŸ‘¤ "Llista fitxers Python"
   
2. El client consulta el LLM
   ğŸ’¬ â†’ ğŸ¤– "Quina eina utilitzar?"
   
3. El LLM decideix l'eina
   ğŸ¤– â†’ ğŸ’¬ "[Ãšs eina:cerca:.:*.py]"
   
4. El client crida el servidor MCP
   ğŸ’¬ â†’ ğŸ”§ {"method": "search_files", ...}
   
5. El servidor executa l'eina
   ğŸ”§ â†’ ğŸ’» Cerca real al sistema
   
6. El servidor retorna resultats
   ğŸ”§ â†’ ğŸ’¬ {"result": ["main.py", ...]}
   
7. El client envia resultats al LLM
   ğŸ’¬ â†’ ğŸ¤– "Fitxers trobats: ..."
   
8. El LLM genera resposta natural
   ğŸ¤– â†’ ğŸ’¬ "He trobat 12 fitxers Python: ..."
   
9. L'usuari veu la resposta
   ğŸ’¬ â†’ ğŸ‘¤ "He trobat 12 fitxers Python: ..."
```

### Flux Mode Agent

```
1. L'usuari introdueix comanda complexa
   ğŸ‘¤ "Descarrega X i desprÃ©s comprimeix Y"
   
2. El client detecta mode agent
   ğŸ’¬ [Detecta paraula clau "i desprÃ©s"]
   
3. El LLM planifica passos
   ğŸ’¬ â†’ ğŸ¤– "Descompon en passos"
   ğŸ¤– â†’ ğŸ’¬ ["download:...", "search:...", "compress:..."]
   
4. El client executa passos seqÃ¼encialment
   ğŸ’¬ â†’ ğŸ”§ Pas 1: DescÃ rrega âœ…
   ğŸ’¬ â†’ ğŸ”§ Pas 2: Cerca âœ…
   ğŸ’¬ â†’ ğŸ”§ Pas 3: CompressiÃ³ âœ…
   
5. El LLM integra resultats
   ğŸ’¬ â†’ ğŸ¤– "Resume tot l'executat"
   ğŸ¤– â†’ ğŸ’¬ "He descarregat, cercat i comprimit..."
   
6. L'usuari veu el resum final
   ğŸ’¬ â†’ ğŸ‘¤ "âœ… Tasca completada: ..."
```

---

## ğŸ“š Recursos Addicionals

### Model Context Protocol (MCP)
- ğŸ“– [EspecificaciÃ³ MCP](https://spec.modelcontextprotocol.io/)
- ğŸ”— [Anthropic MCP GitHub](https://github.com/anthropics/mcp)

### Models Recomanats
- ğŸ¦™ [Llama 3 8B Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)
- ğŸŒŸ [Mistral 7B Instruct](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1)
- ğŸš€ [Mixtral 8x7B](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)

### llama.cpp
- ğŸ”— [llama.cpp GitHub](https://github.com/ggerganov/llama.cpp)
- ğŸ“– [DocumentaciÃ³](https://github.com/ggerganov/llama.cpp/blob/master/README.md)

---

## ğŸ“ Casos d'Ãšs

### Per a Desenvolupadors
- âœ… Automatitzar tasques repetitives
- âœ… Analitzar codi i cercar TODOs
- âœ… Gestionar repositoris Git
- âœ… Generar documentaciÃ³
- âœ… Monitoritzar recursos del sistema

### Per a Administradors de Sistemes
- âœ… Automatitzar cÃ²pies de seguretat
- âœ… Monitoritzar logs
- âœ… Gestionar fitxers de configuraciÃ³
- âœ… Cercar informaciÃ³ als logs
- âœ… Comprimir/descomprimir arxius

### Per a Usuaris AvanÃ§ats
- âœ… Organitzar fitxers automÃ ticament
- âœ… Descarregar i processar contingut web
- âœ… Cercar informaciÃ³ en documents
- âœ… Automatitzar fluxos de treball complexos
- âœ… Integrar amb APIs externes

---

## ğŸ¤ Contribucions

Tens idees per millorar MCP Local? Contribueix!

### Idees per a Noves Eines
- ğŸ“§ Client de correu
- ğŸ“… IntegraciÃ³ amb calendari
- ğŸ—„ï¸ Operacions de base de dades
- ğŸ³ IntegraciÃ³ amb Docker
- ğŸ“Š GeneraciÃ³ d'informes

### Com Contribuir
1. Fes fork del projecte
2. Crea una branca (`git checkout -b feature/nova-eina`)
3. Fes commit dels canvis (`git commit -am 'Afegeix nova eina X'`)
4. Puja a la branca (`git push origin feature/nova-eina`)
5. Obre un Pull Request

---

## ğŸ“„ LlicÃ¨ncia

Aquest projecte estÃ  sota llicÃ¨ncia MIT. Utilitza'l, modifica'l i comparteix-lo lliurement.

```
LlicÃ¨ncia MIT

Copyright (c) 2025 Gustavo Silva Da Costa

Es concedeix permÃ­s gratuÃ¯t a qualsevol persona que obtingui una cÃ²pia
d'aquest programari i dels fitxers de documentaciÃ³ associats (el "Programari")
per tractar el Programari sense restriccions, incloent sense limitaciÃ³ els
drets d'usar, copiar, modificar, fusionar, publicar, distribuir, sublicenciar
i/o vendre cÃ²pies del Programari, i permetre a les persones a les quals se'ls
proporcioni el Programari fer-ho, subjecte a les segÃ¼ents condicions:

L'avÃ­s de copyright anterior i aquest avÃ­s de permÃ­s s'han d'incloure en
totes les cÃ²pies o parts substancials del Programari.

EL PROGRAMARI ES PROPORCIONA "TAL QUAL", SENSE GARANTIA DE CAP TIPUS, EXPLÃCITA
O IMPLÃCITA, INCLOENT PERÃ’ NO LIMITAT A LES GARANTIES DE COMERCIABILITAT,
IDONEÃTAT PER A UN PROPÃ’SIT PARTICULAR I NO INFRACCIÃ“. EN CAP CAS ELS AUTORS
O TITULARS DEL COPYRIGHT SERAN RESPONSABLES DE CAP RECLAMACIÃ“, DANYS O ALTRA
RESPONSABILITAT, JA SIGUI EN UNA ACCIÃ“ CONTRACTUAL, GREUGE O D'ALTRA MANERA,
QUE SORGEIXI DE, FORA DE O EN CONNEXIÃ“ AMB EL PROGRAMARI O L'ÃšS O ALTRES
TRACTAMENTS DEL PROGRAMARI.
```

---

## ğŸ™ AgraÃ¯ments

- Anthropic per proporcionar el concepte de Model Context Protocol
- La comunitat llama.cpp per fer possible l'execuciÃ³ de LLMs localment
- Tothom qui contribueix a l'ecosistema d'IA de codi obert

---

## ğŸ“ Suport

Tens problemes? Preguntes? Suggeriments?

- ğŸ“§ Correu: gsilvadacosta0@gmail.com 
- ğŸ†‡ L'antic Twitter ğŸ˜‚: https://x.com/bibliogalactic

---

<div align="center">

## â­ Si t'agrada aquest projecte, dona-li una estrella a GitHub â­

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                        â•‘
â•‘   Creat amb â¤ï¸ per a la comunitat d'IA local          â•‘
â•‘                                                        â•‘
â•‘   "Donant mans a la IA, una eina cada cop"            â•‘
â•‘                                                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### ğŸ‘¨â€ğŸ’» Autor

**Gustavo Silva Da Costa** (Eto Demerzel) ğŸ¤«

ğŸš€ *Transformant IA local en assistents potents*

</div>

---

**VersiÃ³:** 1.0.0  
**Ãšltima actualitzaciÃ³:** Octubre 2025  
**Estat:** âœ… ProducciÃ³

---
