# ü§ñ Setup Assistent IA Local Millorat

## Descripci√≥

Sistema d‚Äôinstal¬∑laci√≥ automatitzada per a un Assistent IA Local amb capacitats ag√®ntiques avan√ßades. Aquest script configura un entorn complet de desenvolupament per a interactuar amb models LLaMA locals, proporcionant funcionalitats d‚Äôan√†lisi de codi, gesti√≥ d‚Äôarxius i execuci√≥ de comandes del sistema.

## Caracter√≠stiques Principals

### üß† Mode Ag√®ntic Intel¬∑ligent
- **Planificaci√≥ autom√†tica**: Descompon tasques complexes en subtasques espec√≠fiques
- **Lectura autom√†tica d‚Äôarxius**: Analitza autom√†ticament arxius rellevants del projecte
- **S√≠ntesi sense redund√†ncies**: Combina m√∫ltiples an√†lisis eliminant informaci√≥ repetida
- **Verificaci√≥ de qualitat**: Sistema autom√†tic de control de qualitat de respostes

### üîß Funcionalitats Avan√ßades
- **50+ comandes habilitades**: Git, Docker, NPM, Python, i m√©s
- **Protecci√≥ contra comandes perilloses**: Sistema de seguretat integrat
- **Gesti√≥ intel¬∑ligent d‚Äôarxius**: Lectura, escriptura i an√†lisi de codi
- **Configuraci√≥ adaptativa**: S‚Äôajusta autom√†ticament a l‚Äôentorn

### üéØ Arquitectura Modular
- **Core**: Motor principal de l‚Äôassistent
- **LLM Client**: Comunicaci√≥ amb models llama.cpp
- **File Manager**: Gesti√≥ segura d‚Äôarxius
- **Command Runner**: Execuci√≥ controlada de comandes
- **Agentic Extension**: Capacitats ag√®ntiques avan√ßades

## Requisits del Sistema

- **Python 3.11+**
- **llama.cpp** compilat i funcional
- **Model GGUF** compatible
- **Bash 4.0+**
- **Sistema operatiu**: macOS, Linux

## Instal¬∑laci√≥

### 1. Desc√†rrega i Instal¬∑laci√≥
```bash
# Descarregar l‚Äôscript
curl -O https://raw.githubusercontent.com/tu-usuario/setup-asistente/main/setup_asistente.sh

# Fer executable
chmod +x setup_asistente.sh

# Executar instal¬∑laci√≥
./setup_asistente.sh
```

### 2. Configuraci√≥ Interactiva
L‚Äôscript et demanar√†:
- **Directori d‚Äôinstal¬∑laci√≥**: On s‚Äôinstal¬∑lar√† el projecte
- **Ruta del model GGUF**: El teu model de llenguatge local
- **Ruta de llama-cli**: Binari de llama.cpp

### 3. Estructura Generada
```
asistente-ia/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ core/              # Motor principal
‚îÇ   ‚îú‚îÄ‚îÄ llm/               # Client LLM
‚îÇ   ‚îú‚îÄ‚îÄ file_ops/          # Gesti√≥ d‚Äôarxius
‚îÇ   ‚îî‚îÄ‚îÄ commands/          # Execuci√≥ de comandes
‚îú‚îÄ‚îÄ config/                # Configuraci√≥
‚îú‚îÄ‚îÄ tools/                 # Eines addicionals
‚îú‚îÄ‚îÄ tests/                 # Tests del sistema
‚îú‚îÄ‚îÄ logs/                  # Logs d‚Äôexecuci√≥
‚îî‚îÄ‚îÄ examples/              # Exemples d‚Äô√∫s
```

## √ös

### Comandes B√†siques
```bash
# Assistent normal
claudia "explica aquest projecte"

# Mode ag√®ntic
claudia-a "analitza completament l‚Äôarquitectura"

# Mode verbose (veure proc√©s intern)
claudia-deep "investigaci√≥ profunda sobre errors"

# Ajuda completa
claudia-help
```

### Exemples de Comandes Ag√®ntiques
- `"analitza completament l‚Äôestructura del codi"`
- `"investigaci√≥ profunda sobre el rendiment"`
- `"mode ag√®ntic: optimitza tot el codi"`
- `"examina detalladament els errors"`

### Mode Interactiu
```bash
claudia
üí¨ > agentic on
üí¨ > analitza completament aquest projecte
üí¨ > exit
```

## Configuraci√≥ Avan√ßada

### Arxiu de Configuraci√≥
```json
{
  "llm": {
    "model_path": "/ruta/a/tu/modelo.gguf",
    "llama_bin": "/ruta/a/llama-cli",
    "max_tokens": 1024,
    "temperature": 0.7
  },
  "assistant": {
    "safe_mode": false,
    "backup_files": true,
    "supported_extensions": [".py", ".js", ".json", ".md"]
  }
}
```

### Personalitzaci√≥
- **Models**: Canvia la ruta del model a `config/settings.json`
- **Comandes**: Modifica la llista de comandes permeses a `commands/runner.py`
- **Extensions**: Afegeix nous tipus d‚Äôarxiu suportats

## Arquitectura del Sistema

### Components Principals

1. **LocalAssistant**: Classe principal que coordina tots els components
2. **AgenticAssistant**: Extensi√≥ que proporciona capacitats ag√®ntiques
3. **LlamaClient**: Interf√≠cie amb models llama.cpp
4. **FileManager**: Gesti√≥ segura d‚Äôarxius del projecte
5. **CommandRunner**: Execuci√≥ controlada de comandes del sistema

### Flux Ag√®ntic

1. **Planificaci√≥**: Descompon la tasca en subtasques espec√≠fiques
2. **Execuci√≥**: Executa cada subtasca amb context enriquit
3. **S√≠ntesi**: Combina resultats eliminant redund√†ncies
4. **Verificaci√≥**: Valida la qualitat de la resposta final

## Seguretat

### Comandes Prohibides
- `rm`, `rmdir`, `dd`, `shred`
- `sudo`, `su`, `chmod`, `chown`
- `kill`, `reboot`, `shutdown`

### Comandes Permeses
- Eines de desenvolupament: `git`, `npm`, `pip`, `docker`
- An√†lisi d‚Äôarxius: `cat`, `grep`, `find`, `head`, `tail`
- Compilaci√≥: `make`, `cmake`, `gradle`, `maven`

## Soluci√≥ de Problemes

### Error: "llama-cli no trobat"
```bash
# Verificar instal¬∑laci√≥ de llama.cpp
which llama-cli

# Actualitzar ruta a config
vim config/settings.json
```

### Error: "Model no trobat"
```bash
# Verificar ruta del model
ls -la /ruta/a/tu/modelo.gguf

# Actualitzar configuraci√≥
claudia --config config/settings.json
```

### Mode Ag√®ntic no Funciona
```bash
# Verificar mode verbose
claudia-deep "test simple"

# Veure logs
tail -f logs/assistant.log
```

## Contribuci√≥

1. Fork del repositori
2. Crear branca per a la teva feature: `git checkout -b feature/nova-funcionalitat`
3. Commit de canvis: `git commit -am 'Afegir nova funcionalitat'`
4. Push a la branca: `git push origin feature/nova-funcionalitat`
5. Crear Pull Request

## Llic√®ncia

MIT License - Veure arxiu LICENSE per a detalls.

## Autor

**Gustavo Silva da Costa (Eto Demerzel)**

## Versi√≥

**2.0.0** - Sistema ag√®ntic millorat amb planificaci√≥ intel¬∑ligent i s√≠ntesi sense redund√†ncies.

---

*Per a suport addicional, crea un issue al repositori del projecte.*
